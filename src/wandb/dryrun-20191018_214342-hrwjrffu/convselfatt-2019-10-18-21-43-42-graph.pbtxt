node {
  name: "dropout_keep_rate"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
      }
    }
  }
}
node {
  name: "sample_loss_weights/input"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 650
          }
        }
        tensor_content: "\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?\000\000\200?"
      }
    }
  }
}
node {
  name: "sample_loss_weights"
  op: "PlaceholderWithDefault"
  input: "sample_loss_weights/input"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 650
        }
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_keep_rate"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/tokens"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
        dim {
          size: 200
        }
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/tokens_mask"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
        dim {
          size: 200
        }
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\'\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.02433962
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02433962
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 9
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Initializer/random_uniform/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Initializer/random_uniform/max"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Initializer/random_uniform/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Initializer/random_uniform/RandomUniform"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Initializer/random_uniform"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Initializer/random_uniform/mul"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 10000
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/token_embeddings"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/token_embeddings"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\'\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "code_encoder/python/self_attention_encoder/dropout/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 19
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout/random_uniform/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/dropout/random_uniform/max"
  input: "code_encoder/python/self_attention_encoder/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout/random_uniform/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/dropout/random_uniform/RandomUniform"
  input: "code_encoder/python/self_attention_encoder/dropout/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout/random_uniform"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/dropout/random_uniform/mul"
  input: "code_encoder/python/self_attention_encoder/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/dropout_keep_rate"
  input: "code_encoder/python/self_attention_encoder/dropout/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout/Floor"
  op: "Floor"
  input: "code_encoder/python/self_attention_encoder/dropout/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout/div"
  op: "RealDiv"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/read"
  input: "code_encoder/python/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/dropout/div"
  input: "code_encoder/python/self_attention_encoder/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/embedding_lookup/axis"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dropout/mul"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/embedding_lookup"
  op: "GatherV2"
  input: "code_encoder/python/self_attention_encoder/dropout/mul"
  input: "code_encoder/python/self_attention_encoder/tokens"
  input: "code_encoder/python/self_attention_encoder/embedding_lookup/axis"
  attr {
    key: "Taxis"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tparams"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dropout/mul"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/embedding_lookup/Identity"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/embedding_lookup"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\010\000\000\000\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.054126587
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.054126587
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 33
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/max"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/RandomUniform"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Initializer/random_uniform"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/mul"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/bias/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/conv1d/bias"
  input: "code_encoder/python/self_attention_encoder/conv1d/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/bias/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/conv1d/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/dilation_rate"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims"
  op: "ExpandDims"
  input: "code_encoder/python/self_attention_encoder/embedding_lookup/Identity"
  input: "code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims_1/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims_1"
  op: "ExpandDims"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/read"
  input: "code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims_1/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/conv1d/Conv2D"
  op: "Conv2D"
  input: "code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims"
  input: "code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
  attr {
    key: "dilations"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "padding"
    value {
      s: "SAME"
    }
  }
  attr {
    key: "strides"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "use_cudnn_on_gpu"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/conv1d/Squeeze"
  op: "Squeeze"
  input: "code_encoder/python/self_attention_encoder/conv1d/conv1d/Conv2D"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "squeeze_dims"
    value {
      list {
        i: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/BiasAdd"
  op: "BiasAdd"
  input: "code_encoder/python/self_attention_encoder/conv1d/conv1d/Squeeze"
  input: "code_encoder/python/self_attention_encoder/conv1d/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/Tanh"
  op: "Tanh"
  input: "code_encoder/python/self_attention_encoder/conv1d/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_1/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_1/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_1/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_1/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "code_encoder/python/self_attention_encoder/dropout_1/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 56
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_1/random_uniform/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/dropout_1/random_uniform/max"
  input: "code_encoder/python/self_attention_encoder/dropout_1/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_1/random_uniform/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/dropout_1/random_uniform/RandomUniform"
  input: "code_encoder/python/self_attention_encoder/dropout_1/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_1/random_uniform"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/dropout_1/random_uniform/mul"
  input: "code_encoder/python/self_attention_encoder/dropout_1/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_1/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/dropout_keep_rate"
  input: "code_encoder/python/self_attention_encoder/dropout_1/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_1/Floor"
  op: "Floor"
  input: "code_encoder/python/self_attention_encoder/dropout_1/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_1/div"
  op: "RealDiv"
  input: "code_encoder/python/self_attention_encoder/Tanh"
  input: "code_encoder/python/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_1/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/dropout_1/div"
  input: "code_encoder/python/self_attention_encoder/dropout_1/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\010\000\000\000\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.054126587
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.054126587
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 67
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/max"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/RandomUniform"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/mul"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/bias/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/bias"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/bias/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/dilation_rate"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims"
  op: "ExpandDims"
  input: "code_encoder/python/self_attention_encoder/dropout_1/mul"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1"
  op: "ExpandDims"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/read"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/conv1d/Conv2D"
  op: "Conv2D"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
  attr {
    key: "dilations"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "padding"
    value {
      s: "SAME"
    }
  }
  attr {
    key: "strides"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "use_cudnn_on_gpu"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/conv1d/Squeeze"
  op: "Squeeze"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/conv1d/Conv2D"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "squeeze_dims"
    value {
      list {
        i: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/BiasAdd"
  op: "BiasAdd"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/conv1d/Squeeze"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/BiasAdd"
  input: "code_encoder/python/self_attention_encoder/dropout_1/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/Tanh_1"
  op: "Tanh"
  input: "code_encoder/python/self_attention_encoder/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_2/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/Tanh_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_2/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_2/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_2/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "code_encoder/python/self_attention_encoder/dropout_2/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 91
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_2/random_uniform/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/dropout_2/random_uniform/max"
  input: "code_encoder/python/self_attention_encoder/dropout_2/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_2/random_uniform/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/dropout_2/random_uniform/RandomUniform"
  input: "code_encoder/python/self_attention_encoder/dropout_2/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_2/random_uniform"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/dropout_2/random_uniform/mul"
  input: "code_encoder/python/self_attention_encoder/dropout_2/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_2/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/dropout_keep_rate"
  input: "code_encoder/python/self_attention_encoder/dropout_2/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_2/Floor"
  op: "Floor"
  input: "code_encoder/python/self_attention_encoder/dropout_2/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_2/div"
  op: "RealDiv"
  input: "code_encoder/python/self_attention_encoder/Tanh_1"
  input: "code_encoder/python/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dropout_2/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/dropout_2/div"
  input: "code_encoder/python/self_attention_encoder/dropout_2/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/tokens"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/strided_slice"
  op: "StridedSlice"
  input: "code_encoder/python/self_attention_encoder/Shape"
  input: "code_encoder/python/self_attention_encoder/strided_slice/stack"
  input: "code_encoder/python/self_attention_encoder/strided_slice/stack_1"
  input: "code_encoder/python/self_attention_encoder/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/zeros/mul/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 200
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/zeros/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/strided_slice"
  input: "code_encoder/python/self_attention_encoder/zeros/mul/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/zeros/Less/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1000
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/zeros/Less"
  op: "Less"
  input: "code_encoder/python/self_attention_encoder/zeros/mul"
  input: "code_encoder/python/self_attention_encoder/zeros/Less/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/zeros/packed/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 200
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/zeros/packed"
  op: "Pack"
  input: "code_encoder/python/self_attention_encoder/strided_slice"
  input: "code_encoder/python/self_attention_encoder/zeros/packed/1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/zeros/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/zeros/packed"
  input: "code_encoder/python/self_attention_encoder/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/dropout_2/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/strided_slice"
  op: "StridedSlice"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/strided_slice/stack"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/strided_slice/stack_1"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 120
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/mul"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 16
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/Reshape/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/Reshape"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/zeros"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/one_hot/on_value"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/one_hot/off_value"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/one_hot/depth"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 16
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/one_hot"
  op: "OneHot"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/one_hot/depth"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/one_hot/on_value"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/one_hot/off_value"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "TI"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: -1
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/MatMul"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/one_hot"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_1/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 200
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_1/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_1/shape"
  op: "Pack"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/strided_slice"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_1/shape/1"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_1/shape/2"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_1"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_1/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/dropout_2/mul"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 141
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/mul"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/Slice/begin"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/Slice/size"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\310\000\000\000\377\377\377\377"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/Slice"
  op: "Slice"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/read"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/Slice/begin"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/Slice/size"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_2/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\001\000\000\000\310\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_2"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/Slice"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_2/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/add_1"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/add"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Initializer/ones"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Initializer/ones"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean"
  op: "Mean"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/add_1"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/StopGradient"
  op: "StopGradient"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference"
  op: "SquaredDifference"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/add_1"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance"
  op: "Mean"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1e-12
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/Rsqrt"
  op: "Rsqrt"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/Rsqrt"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/add_1"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/read"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/keep_prob"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.89999998
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 179
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/random_uniform/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/random_uniform/max"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/random_uniform/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/random_uniform/RandomUniform"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/random_uniform"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/random_uniform/mul"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/keep_prob"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/Floor"
  op: "Floor"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div"
  op: "RealDiv"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/tokens"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice"
  op: "StridedSlice"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice/stack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice/stack_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/tokens_mask"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_1/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_1/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_1/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_1"
  op: "StridedSlice"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Shape_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_1/stack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_1/stack_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_1/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 200
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape/shape"
  op: "Pack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape/shape/1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape/shape/2"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/tokens_mask"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/ones/mul/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 200
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/ones/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/ones/mul/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/ones/mul_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/ones/mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/ones/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/ones/mul_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/ones/Less/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1000
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/ones/Less"
  op: "Less"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/ones/mul_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/ones/Less/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/ones/packed/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 200
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/ones/packed/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/ones/packed"
  op: "Pack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/ones/packed/1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/ones/packed/2"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/ones/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/ones"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/ones/packed"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/ones/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/ones"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/Shape_2"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_2/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_2/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_2/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_2"
  op: "StridedSlice"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Shape_2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_2/stack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_2/stack_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_2/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_1/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\377\377\377\377\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_1"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_1/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice"
  op: "StridedSlice"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice/stack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice/stack_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice_1/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice_1/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice_1/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice_1"
  op: "StridedSlice"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Shape_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice_1/stack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice_1/stack_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice_1/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 233
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/BiasAdd"
  op: "BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 248
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/BiasAdd"
  op: "BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 263
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/BiasAdd"
  op: "BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 200
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape/shape/3"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 16
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape/shape"
  op: "Pack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape/shape/1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape/shape/2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape/shape/3"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose/perm"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\000\000\000\000\002\000\000\000\001\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose"
  op: "Transpose"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose/perm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 200
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1/shape/3"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 16
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1/shape"
  op: "Pack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1/shape/1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1/shape/2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1/shape/3"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1/perm"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\000\000\000\000\002\000\000\000\001\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1"
  op: "Transpose"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1/perm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul"
  op: "BatchMatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: false
    }
  }
  attr {
    key: "adj_y"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.25
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/ExpandDims"
  op: "ExpandDims"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/sub/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/sub/x"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/mul_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -10000.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/mul_1/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax"
  op: "Softmax"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/keep_prob"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.89999998
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 304
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/max"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/RandomUniform"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/keep_prob"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/Floor"
  op: "Floor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div"
  op: "RealDiv"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 200
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2/shape/3"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 16
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2/shape"
  op: "Pack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2/shape/1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2/shape/2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2/shape/3"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2/perm"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\000\000\000\000\002\000\000\000\001\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2"
  op: "Transpose"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2/perm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_1"
  op: "BatchMatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: false
    }
  }
  attr {
    key: "adj_y"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3/perm"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\000\000\000\000\002\000\000\000\001\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3"
  op: "Transpose"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3/perm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/mul_2/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 200
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/mul_2"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/mul_2/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3/shape"
  op: "Pack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/mul_2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3/shape/1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 330
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd"
  op: "BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/keep_prob"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.89999998
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 346
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/max"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/RandomUniform"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/keep_prob"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/Floor"
  op: "Floor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div"
  op: "RealDiv"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Initializer/ones"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Initializer/ones"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean"
  op: "Mean"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient"
  op: "StopGradient"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference"
  op: "SquaredDifference"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance"
  op: "Mean"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1e-12
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt"
  op: "Rsqrt"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/read"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\000\002\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 380
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 512
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd"
  op: "BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Sqrt/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 2.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Sqrt"
  op: "Sqrt"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Sqrt/x"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv"
  op: "RealDiv"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Sqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf"
  op: "Erf"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add/x"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.5
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul/x"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 404
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd"
  op: "BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/keep_prob"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.89999998
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 420
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/max"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/RandomUniform"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/keep_prob"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/Floor"
  op: "Floor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div"
  op: "RealDiv"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Initializer/ones"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Initializer/ones"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean"
  op: "Mean"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/StopGradient"
  op: "StopGradient"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference"
  op: "SquaredDifference"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance"
  op: "Mean"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1e-12
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt"
  op: "Rsqrt"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/read"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice"
  op: "StridedSlice"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice/stack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice/stack_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice_1/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice_1/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice_1/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice_1"
  op: "StridedSlice"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Shape_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice_1/stack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice_1/stack_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice_1/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 464
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/BiasAdd"
  op: "BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 479
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/BiasAdd"
  op: "BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 494
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/BiasAdd"
  op: "BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 200
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape/shape/3"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 16
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape/shape"
  op: "Pack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape/shape/1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape/shape/2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape/shape/3"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose/perm"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\000\000\000\000\002\000\000\000\001\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose"
  op: "Transpose"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose/perm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 200
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1/shape/3"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 16
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1/shape"
  op: "Pack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1/shape/1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1/shape/2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1/shape/3"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1/perm"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\000\000\000\000\002\000\000\000\001\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1"
  op: "Transpose"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1/perm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul"
  op: "BatchMatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: false
    }
  }
  attr {
    key: "adj_y"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.25
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/ExpandDims"
  op: "ExpandDims"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/sub/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/sub/x"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/mul_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -10000.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/mul_1/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax"
  op: "Softmax"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/keep_prob"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.89999998
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 535
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/max"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/RandomUniform"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/keep_prob"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/Floor"
  op: "Floor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div"
  op: "RealDiv"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 200
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2/shape/3"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 16
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2/shape"
  op: "Pack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2/shape/1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2/shape/2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2/shape/3"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2/perm"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\000\000\000\000\002\000\000\000\001\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2"
  op: "Transpose"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2/perm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_1"
  op: "BatchMatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: false
    }
  }
  attr {
    key: "adj_y"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3/perm"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\000\000\000\000\002\000\000\000\001\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3"
  op: "Transpose"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3/perm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/mul_2/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 200
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/mul_2"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/mul_2/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3/shape"
  op: "Pack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/mul_2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3/shape/1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 561
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd"
  op: "BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/keep_prob"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.89999998
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 577
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/max"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/RandomUniform"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/keep_prob"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/Floor"
  op: "Floor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div"
  op: "RealDiv"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Initializer/ones"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Initializer/ones"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean"
  op: "Mean"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient"
  op: "StopGradient"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference"
  op: "SquaredDifference"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance"
  op: "Mean"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1e-12
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt"
  op: "Rsqrt"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/read"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\000\002\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 611
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 512
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd"
  op: "BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Sqrt/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 2.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Sqrt"
  op: "Sqrt"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Sqrt/x"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv"
  op: "RealDiv"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Sqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf"
  op: "Erf"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add/x"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.5
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul/x"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 635
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd"
  op: "BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/keep_prob"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.89999998
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 651
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/max"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/RandomUniform"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/keep_prob"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/Floor"
  op: "Floor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div"
  op: "RealDiv"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Initializer/ones"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Initializer/ones"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean"
  op: "Mean"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/StopGradient"
  op: "StopGradient"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference"
  op: "SquaredDifference"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance"
  op: "Mean"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1e-12
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt"
  op: "Rsqrt"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/read"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/Shape_3"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_3/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_3/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_3/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_3"
  op: "StridedSlice"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Shape_3"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_3/stack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_3/stack_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_3/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_2/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 200
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_2/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_2/shape"
  op: "Pack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_2/shape/1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_2/shape/2"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_2"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_2/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/Shape_4"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_4/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_4/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_4/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_4"
  op: "StridedSlice"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Shape_4"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_4/stack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_4/stack_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_4/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_3/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 200
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_3/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_3/shape"
  op: "Pack"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_3/shape/1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_3/shape/2"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_3"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_3/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\000\000\000\000\000\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\000\000\000\000\001\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\001\000\000\000\001\000\000\000\001\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/strided_slice"
  op: "StridedSlice"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_3"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/strided_slice/stack"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/strided_slice/stack_1"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 5
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 5
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 0
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/Squeeze"
  op: "Squeeze"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/strided_slice"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "squeeze_dims"
    value {
      list {
        i: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 708
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/mul"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/dense/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/pooler/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/dense/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/pooler/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/dense/bias/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/dense/bias"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/dense/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/pooler/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/dense/bias/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/dense/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/pooler/dense/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/dense/MatMul"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/Squeeze"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/dense/BiasAdd"
  op: "BiasAdd"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/dense/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/dense/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/pooler/dense/Tanh"
  op: "Tanh"
  input: "code_encoder/python/self_attention_encoder/bert/pooler/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/Sum/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/Sum"
  op: "Sum"
  input: "code_encoder/python/self_attention_encoder/tokens_mask"
  input: "code_encoder/python/self_attention_encoder/Sum/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/kernel/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\001\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/kernel/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.21566555
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/kernel/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.21566555
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/kernel/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "code_encoder/python/self_attention_encoder/dense/kernel/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 726
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/kernel/Initializer/random_uniform/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/dense/kernel/Initializer/random_uniform/max"
  input: "code_encoder/python/self_attention_encoder/dense/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/kernel/Initializer/random_uniform/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/dense/kernel/Initializer/random_uniform/RandomUniform"
  input: "code_encoder/python/self_attention_encoder/dense/kernel/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/kernel/Initializer/random_uniform"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/dense/kernel/Initializer/random_uniform/mul"
  input: "code_encoder/python/self_attention_encoder/dense/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 1
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/kernel/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/dense/kernel"
  input: "code_encoder/python/self_attention_encoder/dense/kernel/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/kernel/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/dense/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/axes"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/free"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\000\000\000\001\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/GatherV2/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/GatherV2"
  op: "GatherV2"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/Shape"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/free"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/GatherV2/axis"
  attr {
    key: "Taxis"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tparams"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/GatherV2_1/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/GatherV2_1"
  op: "GatherV2"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/Shape"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/axes"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/GatherV2_1/axis"
  attr {
    key: "Taxis"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tparams"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/Prod"
  op: "Prod"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/GatherV2"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/Prod_1"
  op: "Prod"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/GatherV2_1"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/concat"
  op: "ConcatV2"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/free"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/axes"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/concat/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/stack"
  op: "Pack"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/Prod"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/Prod_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/transpose"
  op: "Transpose"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_3"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/Reshape"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/transpose"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/stack"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/transpose_1/perm"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\000\000\000\001\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/transpose_1"
  op: "Transpose"
  input: "code_encoder/python/self_attention_encoder/dense/kernel/read"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/transpose_1/perm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/Reshape_1/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\001\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/Reshape_1"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/transpose_1"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/Reshape_1/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/MatMul"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/Reshape"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/Const_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/concat_1/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot/concat_1"
  op: "ConcatV2"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/GatherV2"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/Const_2"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/concat_1/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Tensordot"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/MatMul"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/concat_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/Sigmoid"
  op: "Sigmoid"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/ExpandDims"
  op: "ExpandDims"
  input: "code_encoder/python/self_attention_encoder/tokens_mask"
  input: "code_encoder/python/self_attention_encoder/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/mul"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/dense/Sigmoid"
  input: "code_encoder/python/self_attention_encoder/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_3"
  input: "code_encoder/python/self_attention_encoder/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/Sum_1/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/Sum_1"
  op: "Sum"
  input: "code_encoder/python/self_attention_encoder/mul_1"
  input: "code_encoder/python/self_attention_encoder/Sum_1/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/Sum_2/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/Sum_2"
  op: "Sum"
  input: "code_encoder/python/self_attention_encoder/mul"
  input: "code_encoder/python/self_attention_encoder/Sum_2/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/add_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 9.9999999e-09
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/add_1"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/Sum_2"
  input: "code_encoder/python/self_attention_encoder/add_1/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/truediv"
  op: "RealDiv"
  input: "code_encoder/python/self_attention_encoder/Sum_1"
  input: "code_encoder/python/self_attention_encoder/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_encoder/concat/concat_dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "code_encoder/concat"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_keep_rate"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/tokens"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
        dim {
          size: 30
        }
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/tokens_mask"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
        dim {
          size: 30
        }
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\'\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.02433962
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02433962
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "query_encoder/self_attention_encoder/token_embeddings/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 778
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Initializer/random_uniform/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/token_embeddings/Initializer/random_uniform/max"
  input: "query_encoder/self_attention_encoder/token_embeddings/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Initializer/random_uniform/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/token_embeddings/Initializer/random_uniform/RandomUniform"
  input: "query_encoder/self_attention_encoder/token_embeddings/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Initializer/random_uniform"
  op: "Add"
  input: "query_encoder/self_attention_encoder/token_embeddings/Initializer/random_uniform/mul"
  input: "query_encoder/self_attention_encoder/token_embeddings/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 10000
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/token_embeddings"
  input: "query_encoder/self_attention_encoder/token_embeddings/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/token_embeddings"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\'\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "query_encoder/self_attention_encoder/dropout/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 788
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout/random_uniform/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/dropout/random_uniform/max"
  input: "query_encoder/self_attention_encoder/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout/random_uniform/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/dropout/random_uniform/RandomUniform"
  input: "query_encoder/self_attention_encoder/dropout/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout/random_uniform"
  op: "Add"
  input: "query_encoder/self_attention_encoder/dropout/random_uniform/mul"
  input: "query_encoder/self_attention_encoder/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/dropout_keep_rate"
  input: "query_encoder/self_attention_encoder/dropout/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout/Floor"
  op: "Floor"
  input: "query_encoder/self_attention_encoder/dropout/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout/div"
  op: "RealDiv"
  input: "query_encoder/self_attention_encoder/token_embeddings/read"
  input: "query_encoder/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/dropout/div"
  input: "query_encoder/self_attention_encoder/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/embedding_lookup/axis"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dropout/mul"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/embedding_lookup"
  op: "GatherV2"
  input: "query_encoder/self_attention_encoder/dropout/mul"
  input: "query_encoder/self_attention_encoder/tokens"
  input: "query_encoder/self_attention_encoder/embedding_lookup/axis"
  attr {
    key: "Taxis"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tparams"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dropout/mul"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/embedding_lookup/Identity"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/embedding_lookup"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\010\000\000\000\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.054126587
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.054126587
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 802
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/max"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/RandomUniform"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Initializer/random_uniform"
  op: "Add"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/mul"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/conv1d/kernel"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/conv1d/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/bias/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/conv1d/bias"
  input: "query_encoder/self_attention_encoder/conv1d/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/bias/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/conv1d/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/dilation_rate"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims"
  op: "ExpandDims"
  input: "query_encoder/self_attention_encoder/embedding_lookup/Identity"
  input: "query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims_1/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims_1"
  op: "ExpandDims"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/read"
  input: "query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims_1/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/conv1d/Conv2D"
  op: "Conv2D"
  input: "query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims"
  input: "query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
  attr {
    key: "dilations"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "padding"
    value {
      s: "SAME"
    }
  }
  attr {
    key: "strides"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "use_cudnn_on_gpu"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/conv1d/Squeeze"
  op: "Squeeze"
  input: "query_encoder/self_attention_encoder/conv1d/conv1d/Conv2D"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "squeeze_dims"
    value {
      list {
        i: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/BiasAdd"
  op: "BiasAdd"
  input: "query_encoder/self_attention_encoder/conv1d/conv1d/Squeeze"
  input: "query_encoder/self_attention_encoder/conv1d/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/Tanh"
  op: "Tanh"
  input: "query_encoder/self_attention_encoder/conv1d/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_1/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_1/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_1/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_1/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "query_encoder/self_attention_encoder/dropout_1/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 825
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_1/random_uniform/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/dropout_1/random_uniform/max"
  input: "query_encoder/self_attention_encoder/dropout_1/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_1/random_uniform/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/dropout_1/random_uniform/RandomUniform"
  input: "query_encoder/self_attention_encoder/dropout_1/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_1/random_uniform"
  op: "Add"
  input: "query_encoder/self_attention_encoder/dropout_1/random_uniform/mul"
  input: "query_encoder/self_attention_encoder/dropout_1/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_1/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/dropout_keep_rate"
  input: "query_encoder/self_attention_encoder/dropout_1/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_1/Floor"
  op: "Floor"
  input: "query_encoder/self_attention_encoder/dropout_1/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_1/div"
  op: "RealDiv"
  input: "query_encoder/self_attention_encoder/Tanh"
  input: "query_encoder/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_1/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/dropout_1/div"
  input: "query_encoder/self_attention_encoder/dropout_1/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\010\000\000\000\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.054126587
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.054126587
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 836
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/max"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/RandomUniform"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform"
  op: "Add"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/mul"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/bias/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/conv1d_1/bias"
  input: "query_encoder/self_attention_encoder/conv1d_1/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/bias/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/conv1d_1/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/dilation_rate"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims"
  op: "ExpandDims"
  input: "query_encoder/self_attention_encoder/dropout_1/mul"
  input: "query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1"
  op: "ExpandDims"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/read"
  input: "query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/conv1d/Conv2D"
  op: "Conv2D"
  input: "query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims"
  input: "query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
  attr {
    key: "dilations"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "padding"
    value {
      s: "SAME"
    }
  }
  attr {
    key: "strides"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "use_cudnn_on_gpu"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/conv1d/Squeeze"
  op: "Squeeze"
  input: "query_encoder/self_attention_encoder/conv1d_1/conv1d/Conv2D"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "squeeze_dims"
    value {
      list {
        i: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/BiasAdd"
  op: "BiasAdd"
  input: "query_encoder/self_attention_encoder/conv1d_1/conv1d/Squeeze"
  input: "query_encoder/self_attention_encoder/conv1d_1/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/conv1d_1/BiasAdd"
  input: "query_encoder/self_attention_encoder/dropout_1/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/Tanh_1"
  op: "Tanh"
  input: "query_encoder/self_attention_encoder/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_2/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/Tanh_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_2/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_2/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_2/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "query_encoder/self_attention_encoder/dropout_2/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 860
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_2/random_uniform/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/dropout_2/random_uniform/max"
  input: "query_encoder/self_attention_encoder/dropout_2/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_2/random_uniform/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/dropout_2/random_uniform/RandomUniform"
  input: "query_encoder/self_attention_encoder/dropout_2/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_2/random_uniform"
  op: "Add"
  input: "query_encoder/self_attention_encoder/dropout_2/random_uniform/mul"
  input: "query_encoder/self_attention_encoder/dropout_2/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_2/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/dropout_keep_rate"
  input: "query_encoder/self_attention_encoder/dropout_2/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_2/Floor"
  op: "Floor"
  input: "query_encoder/self_attention_encoder/dropout_2/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_2/div"
  op: "RealDiv"
  input: "query_encoder/self_attention_encoder/Tanh_1"
  input: "query_encoder/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dropout_2/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/dropout_2/div"
  input: "query_encoder/self_attention_encoder/dropout_2/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/tokens"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/strided_slice"
  op: "StridedSlice"
  input: "query_encoder/self_attention_encoder/Shape"
  input: "query_encoder/self_attention_encoder/strided_slice/stack"
  input: "query_encoder/self_attention_encoder/strided_slice/stack_1"
  input: "query_encoder/self_attention_encoder/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/zeros/mul/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 30
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/zeros/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/strided_slice"
  input: "query_encoder/self_attention_encoder/zeros/mul/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/zeros/Less/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1000
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/zeros/Less"
  op: "Less"
  input: "query_encoder/self_attention_encoder/zeros/mul"
  input: "query_encoder/self_attention_encoder/zeros/Less/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/zeros/packed/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 30
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/zeros/packed"
  op: "Pack"
  input: "query_encoder/self_attention_encoder/strided_slice"
  input: "query_encoder/self_attention_encoder/zeros/packed/1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/zeros/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/zeros/packed"
  input: "query_encoder/self_attention_encoder/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/dropout_2/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/strided_slice"
  op: "StridedSlice"
  input: "query_encoder/self_attention_encoder/bert/embeddings/Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/strided_slice/stack"
  input: "query_encoder/self_attention_encoder/bert/embeddings/strided_slice/stack_1"
  input: "query_encoder/self_attention_encoder/bert/embeddings/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 889
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/mul"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 16
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/Reshape/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/Reshape"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/zeros"
  input: "query_encoder/self_attention_encoder/bert/embeddings/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/one_hot/on_value"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/one_hot/off_value"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/one_hot/depth"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 16
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/one_hot"
  op: "OneHot"
  input: "query_encoder/self_attention_encoder/bert/embeddings/Reshape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/one_hot/depth"
  input: "query_encoder/self_attention_encoder/bert/embeddings/one_hot/on_value"
  input: "query_encoder/self_attention_encoder/bert/embeddings/one_hot/off_value"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "TI"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: -1
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/MatMul"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/embeddings/one_hot"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/Reshape_1/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 30
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/Reshape_1/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/Reshape_1/shape"
  op: "Pack"
  input: "query_encoder/self_attention_encoder/bert/embeddings/strided_slice"
  input: "query_encoder/self_attention_encoder/bert/embeddings/Reshape_1/shape/1"
  input: "query_encoder/self_attention_encoder/bert/embeddings/Reshape_1/shape/2"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/Reshape_1"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/MatMul"
  input: "query_encoder/self_attention_encoder/bert/embeddings/Reshape_1/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/dropout_2/mul"
  input: "query_encoder/self_attention_encoder/bert/embeddings/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 910
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/mul"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/Slice/begin"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/Slice/size"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\036\000\000\000\377\377\377\377"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/Slice"
  op: "Slice"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/read"
  input: "query_encoder/self_attention_encoder/bert/embeddings/Slice/begin"
  input: "query_encoder/self_attention_encoder/bert/embeddings/Slice/size"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/Reshape_2/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\001\000\000\000\036\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/Reshape_2"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/Slice"
  input: "query_encoder/self_attention_encoder/bert/embeddings/Reshape_2/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/add_1"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/embeddings/add"
  input: "query_encoder/self_attention_encoder/bert/embeddings/Reshape_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Initializer/ones"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Initializer/ones"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean"
  op: "Mean"
  input: "query_encoder/self_attention_encoder/bert/embeddings/add_1"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/StopGradient"
  op: "StopGradient"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference"
  op: "SquaredDifference"
  input: "query_encoder/self_attention_encoder/bert/embeddings/add_1"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance"
  op: "Mean"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1e-12
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/Rsqrt"
  op: "Rsqrt"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/Rsqrt"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/embeddings/add_1"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/read"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/dropout/keep_prob"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.89999998
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/dropout/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/dropout/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/dropout/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/dropout/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 948
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/dropout/random_uniform/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/random_uniform/max"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/dropout/random_uniform/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/random_uniform/RandomUniform"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/dropout/random_uniform"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/random_uniform/mul"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/dropout/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/keep_prob"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/dropout/Floor"
  op: "Floor"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/dropout/div"
  op: "RealDiv"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/dropout/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/div"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/tokens"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice"
  op: "StridedSlice"
  input: "query_encoder/self_attention_encoder/bert/encoder/Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice/stack"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice/stack_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/tokens_mask"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_1/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_1/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_1/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_1"
  op: "StridedSlice"
  input: "query_encoder/self_attention_encoder/bert/encoder/Shape_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_1/stack"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_1/stack_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_1/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/Reshape/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/Reshape/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 30
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/Reshape/shape"
  op: "Pack"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape/shape/1"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape/shape/2"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/Reshape"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/tokens_mask"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/ones/mul/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 30
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/ones/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice"
  input: "query_encoder/self_attention_encoder/bert/encoder/ones/mul/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/ones/mul_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/ones/mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/ones/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/ones/mul_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/ones/Less/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1000
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/ones/Less"
  op: "Less"
  input: "query_encoder/self_attention_encoder/bert/encoder/ones/mul_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/ones/Less/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/ones/packed/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 30
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/ones/packed/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/ones/packed"
  op: "Pack"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice"
  input: "query_encoder/self_attention_encoder/bert/encoder/ones/packed/1"
  input: "query_encoder/self_attention_encoder/bert/encoder/ones/packed/2"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/ones/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/ones"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/ones/packed"
  input: "query_encoder/self_attention_encoder/bert/encoder/ones/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/ones"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/Shape_2"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_2/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_2/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_2/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_2"
  op: "StridedSlice"
  input: "query_encoder/self_attention_encoder/bert/encoder/Shape_2"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_2/stack"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_2/stack_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_2/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/Reshape_1/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\377\377\377\377\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/Reshape_1"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_1/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice"
  op: "StridedSlice"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice/stack"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice/stack_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice_1/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice_1/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice_1/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice_1"
  op: "StridedSlice"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Shape_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice_1/stack"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice_1/stack_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/strided_slice_1/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1002
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/BiasAdd"
  op: "BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1017
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/BiasAdd"
  op: "BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1032
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/BiasAdd"
  op: "BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 30
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape/shape/3"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 16
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape/shape"
  op: "Pack"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape/shape/1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape/shape/2"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape/shape/3"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose/perm"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\000\000\000\000\002\000\000\000\001\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose"
  op: "Transpose"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose/perm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 30
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1/shape/3"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 16
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1/shape"
  op: "Pack"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1/shape/1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1/shape/2"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1/shape/3"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1/perm"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\000\000\000\000\002\000\000\000\001\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1"
  op: "Transpose"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1/perm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul"
  op: "BatchMatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: false
    }
  }
  attr {
    key: "adj_y"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.25
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/ExpandDims"
  op: "ExpandDims"
  input: "query_encoder/self_attention_encoder/bert/encoder/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/sub/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/sub/x"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/mul_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -10000.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/mul_1/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax"
  op: "Softmax"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/keep_prob"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.89999998
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1073
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/max"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/RandomUniform"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/keep_prob"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/Floor"
  op: "Floor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div"
  op: "RealDiv"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 30
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2/shape/3"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 16
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2/shape"
  op: "Pack"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2/shape/1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2/shape/2"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2/shape/3"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2/perm"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\000\000\000\000\002\000\000\000\001\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2"
  op: "Transpose"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2/perm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_1"
  op: "BatchMatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: false
    }
  }
  attr {
    key: "adj_y"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3/perm"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\000\000\000\000\002\000\000\000\001\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3"
  op: "Transpose"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3/perm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/mul_2/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 30
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/mul_2"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/mul_2/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3/shape"
  op: "Pack"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/mul_2"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3/shape/1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1099
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd"
  op: "BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/keep_prob"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.89999998
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1115
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/max"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/RandomUniform"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/keep_prob"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/Floor"
  op: "Floor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div"
  op: "RealDiv"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Initializer/ones"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Initializer/ones"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean"
  op: "Mean"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient"
  op: "StopGradient"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference"
  op: "SquaredDifference"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance"
  op: "Mean"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1e-12
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt"
  op: "Rsqrt"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/read"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\000\002\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1149
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 512
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd"
  op: "BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Sqrt/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 2.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Sqrt"
  op: "Sqrt"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Sqrt/x"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv"
  op: "RealDiv"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Sqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf"
  op: "Erf"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add/x"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.5
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul/x"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1173
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd"
  op: "BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/keep_prob"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.89999998
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1189
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/max"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/RandomUniform"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/keep_prob"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/Floor"
  op: "Floor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div"
  op: "RealDiv"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Initializer/ones"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Initializer/ones"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean"
  op: "Mean"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/StopGradient"
  op: "StopGradient"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference"
  op: "SquaredDifference"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance"
  op: "Mean"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1e-12
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt"
  op: "Rsqrt"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/read"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice"
  op: "StridedSlice"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice/stack"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice/stack_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice_1/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice_1/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice_1/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice_1"
  op: "StridedSlice"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Shape_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice_1/stack"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice_1/stack_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/strided_slice_1/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1233
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/BiasAdd"
  op: "BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1248
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/BiasAdd"
  op: "BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1263
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/BiasAdd"
  op: "BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 30
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape/shape/3"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 16
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape/shape"
  op: "Pack"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape/shape/1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape/shape/2"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape/shape/3"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose/perm"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\000\000\000\000\002\000\000\000\001\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose"
  op: "Transpose"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose/perm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 30
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1/shape/3"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 16
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1/shape"
  op: "Pack"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1/shape/1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1/shape/2"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1/shape/3"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1/perm"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\000\000\000\000\002\000\000\000\001\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1"
  op: "Transpose"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1/perm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul"
  op: "BatchMatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: false
    }
  }
  attr {
    key: "adj_y"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.25
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/ExpandDims"
  op: "ExpandDims"
  input: "query_encoder/self_attention_encoder/bert/encoder/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/sub/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/sub/x"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/mul_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -10000.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/mul_1/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax"
  op: "Softmax"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/keep_prob"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.89999998
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1304
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/max"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/RandomUniform"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/keep_prob"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/Floor"
  op: "Floor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div"
  op: "RealDiv"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 30
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2/shape/3"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 16
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2/shape"
  op: "Pack"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2/shape/1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2/shape/2"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2/shape/3"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2/perm"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\000\000\000\000\002\000\000\000\001\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2"
  op: "Transpose"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2/perm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_1"
  op: "BatchMatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: false
    }
  }
  attr {
    key: "adj_y"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3/perm"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\000\000\000\000\002\000\000\000\001\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3"
  op: "Transpose"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3/perm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/mul_2/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 30
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/mul_2"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/mul_2/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3/shape"
  op: "Pack"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/mul_2"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3/shape/1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1330
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd"
  op: "BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/keep_prob"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.89999998
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1346
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/max"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/RandomUniform"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/keep_prob"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/Floor"
  op: "Floor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div"
  op: "RealDiv"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Initializer/ones"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Initializer/ones"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean"
  op: "Mean"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient"
  op: "StopGradient"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference"
  op: "SquaredDifference"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance"
  op: "Mean"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1e-12
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt"
  op: "Rsqrt"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/read"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\000\002\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1380
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 512
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd"
  op: "BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Sqrt/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 2.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Sqrt"
  op: "Sqrt"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Sqrt/x"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv"
  op: "RealDiv"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Sqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf"
  op: "Erf"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add/x"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.5
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul/x"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1404
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd"
  op: "BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/keep_prob"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.89999998
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1420
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/max"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/RandomUniform"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/keep_prob"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/Floor"
  op: "Floor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div"
  op: "RealDiv"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Initializer/ones"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Initializer/ones"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean"
  op: "Mean"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/StopGradient"
  op: "StopGradient"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference"
  op: "SquaredDifference"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance"
  op: "Mean"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1e-12
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt"
  op: "Rsqrt"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/read"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/Shape_3"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_3/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_3/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_3/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_3"
  op: "StridedSlice"
  input: "query_encoder/self_attention_encoder/bert/encoder/Shape_3"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_3/stack"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_3/stack_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_3/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/Reshape_2/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 30
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/Reshape_2/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/Reshape_2/shape"
  op: "Pack"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_2/shape/1"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_2/shape/2"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/Reshape_2"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_2/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/Shape_4"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_4/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_4/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_4/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_4"
  op: "StridedSlice"
  input: "query_encoder/self_attention_encoder/bert/encoder/Shape_4"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_4/stack"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_4/stack_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_4/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/Reshape_3/shape/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 30
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/Reshape_3/shape/2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/Reshape_3/shape"
  op: "Pack"
  input: "query_encoder/self_attention_encoder/bert/encoder/strided_slice_2"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_3/shape/1"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_3/shape/2"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/Reshape_3"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_3/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\000\000\000\000\000\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\000\000\000\000\001\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\001\000\000\000\001\000\000\000\001\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/strided_slice"
  op: "StridedSlice"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_3"
  input: "query_encoder/self_attention_encoder/bert/pooler/strided_slice/stack"
  input: "query_encoder/self_attention_encoder/bert/pooler/strided_slice/stack_1"
  input: "query_encoder/self_attention_encoder/bert/pooler/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 5
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 5
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 0
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/Squeeze"
  op: "Squeeze"
  input: "query_encoder/self_attention_encoder/bert/pooler/strided_slice"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "squeeze_dims"
    value {
      list {
        i: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/pooler/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/mean"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/pooler/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/stddev"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/pooler/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.02
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  op: "TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/pooler/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1477
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/TruncatedNormal"
  input: "query_encoder/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/stddev"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/pooler/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/mul"
  input: "query_encoder/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/pooler/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/dense/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/pooler/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/dense/kernel/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/pooler/dense/kernel"
  input: "query_encoder/self_attention_encoder/bert/pooler/dense/kernel/Initializer/truncated_normal"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/pooler/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/dense/kernel/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/pooler/dense/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/pooler/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/dense/bias/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/pooler/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/dense/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/pooler/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/dense/bias/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/pooler/dense/bias"
  input: "query_encoder/self_attention_encoder/bert/pooler/dense/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/pooler/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/dense/bias/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/pooler/dense/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/pooler/dense/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/dense/MatMul"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/pooler/Squeeze"
  input: "query_encoder/self_attention_encoder/bert/pooler/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/dense/BiasAdd"
  op: "BiasAdd"
  input: "query_encoder/self_attention_encoder/bert/pooler/dense/MatMul"
  input: "query_encoder/self_attention_encoder/bert/pooler/dense/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/pooler/dense/Tanh"
  op: "Tanh"
  input: "query_encoder/self_attention_encoder/bert/pooler/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/Sum/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/Sum"
  op: "Sum"
  input: "query_encoder/self_attention_encoder/tokens_mask"
  input: "query_encoder/self_attention_encoder/Sum/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/kernel/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\001\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/kernel/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.21566555
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/kernel/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.21566555
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/kernel/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "query_encoder/self_attention_encoder/dense/kernel/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 1495
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/kernel/Initializer/random_uniform/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/dense/kernel/Initializer/random_uniform/max"
  input: "query_encoder/self_attention_encoder/dense/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/kernel/Initializer/random_uniform/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/dense/kernel/Initializer/random_uniform/RandomUniform"
  input: "query_encoder/self_attention_encoder/dense/kernel/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/kernel/Initializer/random_uniform"
  op: "Add"
  input: "query_encoder/self_attention_encoder/dense/kernel/Initializer/random_uniform/mul"
  input: "query_encoder/self_attention_encoder/dense/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 1
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/kernel/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/dense/kernel"
  input: "query_encoder/self_attention_encoder/dense/kernel/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/kernel/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/dense/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/axes"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/free"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\000\000\000\001\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/GatherV2/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/GatherV2"
  op: "GatherV2"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/Shape"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/free"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/GatherV2/axis"
  attr {
    key: "Taxis"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tparams"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/GatherV2_1/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/GatherV2_1"
  op: "GatherV2"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/Shape"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/axes"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/GatherV2_1/axis"
  attr {
    key: "Taxis"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tparams"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/Prod"
  op: "Prod"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/GatherV2"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/Prod_1"
  op: "Prod"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/GatherV2_1"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/concat"
  op: "ConcatV2"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/free"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/axes"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/concat/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/stack"
  op: "Pack"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/Prod"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/Prod_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/transpose"
  op: "Transpose"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_3"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/Reshape"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/transpose"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/stack"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/transpose_1/perm"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\000\000\000\001\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/transpose_1"
  op: "Transpose"
  input: "query_encoder/self_attention_encoder/dense/kernel/read"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/transpose_1/perm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/Reshape_1/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\001\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/Reshape_1"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/transpose_1"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/Reshape_1/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/MatMul"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/Reshape"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/Const_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/concat_1/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot/concat_1"
  op: "ConcatV2"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/GatherV2"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/Const_2"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/concat_1/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Tensordot"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/MatMul"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/concat_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/Sigmoid"
  op: "Sigmoid"
  input: "query_encoder/self_attention_encoder/dense/Tensordot"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/ExpandDims"
  op: "ExpandDims"
  input: "query_encoder/self_attention_encoder/tokens_mask"
  input: "query_encoder/self_attention_encoder/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/mul"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/dense/Sigmoid"
  input: "query_encoder/self_attention_encoder/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_3"
  input: "query_encoder/self_attention_encoder/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/Sum_1/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/Sum_1"
  op: "Sum"
  input: "query_encoder/self_attention_encoder/mul_1"
  input: "query_encoder/self_attention_encoder/Sum_1/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/Sum_2/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/Sum_2"
  op: "Sum"
  input: "query_encoder/self_attention_encoder/mul"
  input: "query_encoder/self_attention_encoder/Sum_2/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/add_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 9.9999999e-09
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/add_1"
  op: "Add"
  input: "query_encoder/self_attention_encoder/Sum_2"
  input: "query_encoder/self_attention_encoder/add_1/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/truediv"
  op: "RealDiv"
  input: "query_encoder/self_attention_encoder/Sum_1"
  input: "query_encoder/self_attention_encoder/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "code_query_cooccurrence_logits"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/truediv"
  input: "code_encoder/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "Shape"
  op: "Shape"
  input: "code_encoder/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "strided_slice"
  op: "StridedSlice"
  input: "Shape"
  input: "strided_slice/stack"
  input: "strided_slice/stack_1"
  input: "strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "range/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "range/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "range"
  op: "Range"
  input: "range/start"
  input: "strided_slice"
  input: "range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "SparseSoftmaxCrossEntropyWithLogits/Shape"
  op: "Shape"
  input: "range"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"
  op: "SparseSoftmaxCrossEntropyWithLogits"
  input: "code_query_cooccurrence_logits"
  input: "range"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tlabels"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "mul"
  op: "Mul"
  input: "SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"
  input: "sample_loss_weights"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "Sum"
  op: "Sum"
  input: "mul"
  input: "Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "Sum_1"
  op: "Sum"
  input: "sample_loss_weights"
  input: "Const_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "truediv"
  op: "RealDiv"
  input: "Sum"
  input: "Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "DiagPart"
  op: "DiagPart"
  input: "code_query_cooccurrence_logits"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "ExpandDims"
  op: "ExpandDims"
  input: "DiagPart"
  input: "ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "GreaterEqual"
  op: "GreaterEqual"
  input: "code_query_cooccurrence_logits"
  input: "ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "ToFloat"
  op: "Cast"
  input: "GreaterEqual"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_BOOL
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "Sum_2/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "Sum_2"
  op: "Sum"
  input: "ToFloat"
  input: "Sum_2/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "truediv_1/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "truediv_1"
  op: "RealDiv"
  input: "truediv_1/x"
  input: "Sum_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/grad_ys_0"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "gradients/Fill"
  op: "Fill"
  input: "gradients/Shape"
  input: "gradients/grad_ys_0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/truediv_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/truediv_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/truediv_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/truediv_grad/Shape"
  input: "gradients/truediv_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/truediv_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/Fill"
  input: "Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/truediv_grad/Sum"
  op: "Sum"
  input: "gradients/truediv_grad/RealDiv"
  input: "gradients/truediv_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/truediv_grad/Reshape"
  op: "Reshape"
  input: "gradients/truediv_grad/Sum"
  input: "gradients/truediv_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/truediv_grad/Neg"
  op: "Neg"
  input: "Sum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/truediv_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/truediv_grad/Neg"
  input: "Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/truediv_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/truediv_grad/RealDiv_1"
  input: "Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/truediv_grad/mul"
  op: "Mul"
  input: "gradients/Fill"
  input: "gradients/truediv_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/truediv_grad/Sum_1"
  op: "Sum"
  input: "gradients/truediv_grad/mul"
  input: "gradients/truediv_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/truediv_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/truediv_grad/Sum_1"
  input: "gradients/truediv_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/Sum_grad/Reshape/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/Sum_grad/Reshape"
  op: "Reshape"
  input: "gradients/truediv_grad/Reshape"
  input: "gradients/Sum_grad/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/Sum_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 650
      }
    }
  }
}
node {
  name: "gradients/Sum_grad/Tile"
  op: "Tile"
  input: "gradients/Sum_grad/Reshape"
  input: "gradients/Sum_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/mul_grad/Shape"
  op: "Shape"
  input: "SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/mul_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 650
      }
    }
  }
}
node {
  name: "gradients/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/mul_grad/Shape"
  input: "gradients/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/mul_grad/Mul"
  op: "Mul"
  input: "gradients/Sum_grad/Tile"
  input: "sample_loss_weights"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/mul_grad/Sum"
  op: "Sum"
  input: "gradients/mul_grad/Mul"
  input: "gradients/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/mul_grad/Sum"
  input: "gradients/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/mul_grad/Mul_1"
  op: "Mul"
  input: "SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"
  input: "gradients/Sum_grad/Tile"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/mul_grad/Mul_1"
  input: "gradients/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/mul_grad/Sum_1"
  input: "gradients/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/zeros_like"
  op: "ZerosLike"
  input: "SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient"
  op: "PreventGradient"
  input: "SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "message"
    value {
      s: "Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\'s interaction with tf.gradients()"
    }
  }
}
node {
  name: "gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims"
  op: "ExpandDims"
  input: "gradients/mul_grad/Reshape"
  input: "gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  op: "Mul"
  input: "gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims"
  input: "gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_query_cooccurrence_logits_grad/MatMul"
  op: "MatMul"
  input: "gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  input: "code_encoder/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_query_cooccurrence_logits_grad/MatMul_1"
  op: "MatMul"
  input: "gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  input: "query_encoder/self_attention_encoder/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/truediv_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/truediv_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/truediv_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/truediv_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/truediv_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/truediv_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/code_query_cooccurrence_logits_grad/MatMul"
  input: "query_encoder/self_attention_encoder/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/truediv_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/truediv_grad/RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/truediv_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/truediv_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/truediv_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/truediv_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/truediv_grad/Neg"
  op: "Neg"
  input: "query_encoder/self_attention_encoder/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/truediv_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/truediv_grad/Neg"
  input: "query_encoder/self_attention_encoder/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/truediv_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/truediv_grad/RealDiv_1"
  input: "query_encoder/self_attention_encoder/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/truediv_grad/mul"
  op: "Mul"
  input: "gradients/code_query_cooccurrence_logits_grad/MatMul"
  input: "gradients/query_encoder/self_attention_encoder/truediv_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/truediv_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/truediv_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/truediv_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/truediv_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/truediv_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/truediv_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 3
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/Sum_1/reduction_indices"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/mod"
  op: "FloorMod"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/add"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/range"
  op: "Range"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/range/start"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Size"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Fill"
  op: "Fill"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Shape_1"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/range"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/mod"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Maximum"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/truediv_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Tile"
  op: "Tile"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/add_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/Sum_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/add_1_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/add_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/add_1_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/add_1_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/truediv_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/add_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/add_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/add_1_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/add_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/add_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/truediv_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/add_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/add_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/add_1_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/code_query_cooccurrence_logits_grad/MatMul_1"
  input: "code_encoder/python/self_attention_encoder/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/Neg"
  op: "Neg"
  input: "code_encoder/python/self_attention_encoder/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/Neg"
  input: "code_encoder/python/self_attention_encoder/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/RealDiv_1"
  input: "code_encoder/python/self_attention_encoder/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/mul"
  op: "Mul"
  input: "gradients/code_query_cooccurrence_logits_grad/MatMul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/mul_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/mul_1_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/mul_1_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/mul_1_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Tile"
  input: "query_encoder/self_attention_encoder/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/mul_1_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/mul_1_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/mul_1_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_3"
  input: "gradients/query_encoder/self_attention_encoder/Sum_1_grad/Tile"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/mul_1_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/mul_1_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 3
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/Sum_2/reduction_indices"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/mod"
  op: "FloorMod"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/add"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/range"
  op: "Range"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/range/start"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Size"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Fill"
  op: "Fill"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Shape_1"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/range"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/mod"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Maximum"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/add_1_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Tile"
  op: "Tile"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 3
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/Sum_1/reduction_indices"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/mod"
  op: "FloorMod"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/add"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/range"
  op: "Range"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/range/start"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Size"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Fill"
  op: "Fill"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Shape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/range"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/mod"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Maximum"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Tile"
  op: "Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/add_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/Sum_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/add_1_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/add_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/add_1_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/add_1_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/add_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/add_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/add_1_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/add_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/add_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/truediv_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/add_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/add_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/add_1_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN"
  op: "AddN"
  input: "gradients/query_encoder/self_attention_encoder/mul_1_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/Sum_2_grad/Tile"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/mul_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/dense/Sigmoid"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/mul_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/mul_grad/Mul"
  op: "Mul"
  input: "gradients/AddN"
  input: "query_encoder/self_attention_encoder/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/dense/Sigmoid"
  input: "gradients/AddN"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Tile"
  input: "code_encoder/python/self_attention_encoder/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_3"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_1_grad/Tile"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 3
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/Sum_2/reduction_indices"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/mod"
  op: "FloorMod"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/add"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/range"
  op: "Range"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/range/start"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Size"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Fill"
  op: "Fill"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Shape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/range"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/mod"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Maximum"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/add_1_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Tile"
  op: "Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dense/Sigmoid_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "query_encoder/self_attention_encoder/dense/Sigmoid"
  input: "gradients/query_encoder/self_attention_encoder/mul_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_1"
  op: "AddN"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/Sum_2_grad/Tile"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/mul_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/dense/Sigmoid"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/mul_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/mul_grad/Mul"
  op: "Mul"
  input: "gradients/AddN_1"
  input: "code_encoder/python/self_attention_encoder/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/dense/Sigmoid"
  input: "gradients/AddN_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dense/Tensordot_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dense/Tensordot_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dense/Sigmoid_grad/SigmoidGrad"
  input: "gradients/query_encoder/self_attention_encoder/dense/Tensordot_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dense/Sigmoid_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "code_encoder/python/self_attention_encoder/dense/Sigmoid"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/query_encoder/self_attention_encoder/dense/Tensordot_grad/Reshape"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dense/Tensordot_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dense/Sigmoid_grad/SigmoidGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/Reshape_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/transpose"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/Reshape_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/MatMul_grad/MatMul"
  input: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/Reshape_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/Reshape_1_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\001\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/Reshape_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/MatMul_grad/MatMul_1"
  input: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/Reshape_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/transpose_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/concat"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/transpose_grad/transpose"
  op: "Transpose"
  input: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/Reshape_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/transpose_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/transpose_1_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "query_encoder/self_attention_encoder/dense/Tensordot/transpose_1/perm"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/transpose_1_grad/transpose"
  op: "Transpose"
  input: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/Reshape_1_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/transpose_1_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/Reshape_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/transpose"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/Reshape_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/MatMul_grad/MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/Reshape_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/Reshape_1_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\001\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/Reshape_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/MatMul_grad/MatMul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/Reshape_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_2"
  op: "AddN"
  input: "gradients/query_encoder/self_attention_encoder/mul_1_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/transpose_grad/transpose"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/Reshape_3_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/Reshape_3_grad/Reshape"
  op: "Reshape"
  input: "gradients/AddN_2"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/Reshape_3_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/transpose_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/concat"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/transpose_grad/transpose"
  op: "Transpose"
  input: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/Reshape_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/transpose_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/transpose_1_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "code_encoder/python/self_attention_encoder/dense/Tensordot/transpose_1/perm"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/transpose_1_grad/transpose"
  op: "Transpose"
  input: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/Reshape_1_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/transpose_1_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/Reshape_3_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/Reshape_3_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_3"
  op: "AddN"
  input: "gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/transpose_grad/transpose"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/Reshape_3_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/Reshape_3_grad/Reshape"
  op: "Reshape"
  input: "gradients/AddN_3"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/Reshape_3_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Neg"
  op: "Neg"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Neg"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/Reshape_3_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/Reshape_3_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Neg"
  op: "Neg"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Neg"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_4"
  op: "AddN"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Mul"
  op: "Mul"
  input: "gradients/AddN_4"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/AddN_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  op: "RsqrtGrad"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_5"
  op: "AddN"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Mul"
  op: "Mul"
  input: "gradients/AddN_5"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/AddN_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  op: "RsqrtGrad"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance/reduction_indices"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/mod"
  op: "FloorMod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/add"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/range"
  op: "Range"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/range/start"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Size"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Fill"
  op: "Fill"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/range"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/mod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Maximum"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Tile"
  op: "Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape_2"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape_3"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Prod"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape_2"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Prod_1"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape_3"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Prod_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Cast"
  op: "Cast"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/truediv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/scalar"
  op: "Const"
  input: "^gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 2.0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/scalar"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/StopGradient"
  input: "^gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Neg"
  op: "Neg"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance/reduction_indices"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/mod"
  op: "FloorMod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/add"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/range"
  op: "Range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/range/start"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Size"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Fill"
  op: "Fill"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/mod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Maximum"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Tile"
  op: "Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape_2"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape_3"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Prod"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape_2"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Prod_1"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Shape_3"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Prod_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Cast"
  op: "Cast"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/truediv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/scalar"
  op: "Const"
  input: "^gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 2.0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/scalar"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/StopGradient"
  input: "^gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Neg"
  op: "Neg"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean/reduction_indices"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/mod"
  op: "FloorMod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/add"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/range"
  op: "Range"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/range/start"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Size"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Fill"
  op: "Fill"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/range"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/mod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Maximum"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Tile"
  op: "Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape_2"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape_3"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Prod"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape_2"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Prod_1"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape_3"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Prod_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Cast"
  op: "Cast"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/truediv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_6"
  op: "AddN"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/truediv"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_6"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_6"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean/reduction_indices"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/mod"
  op: "FloorMod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/add"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/range"
  op: "Range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/range/start"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Size"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Fill"
  op: "Fill"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/mod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Maximum"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Tile"
  op: "Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape_2"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape_3"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Prod"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape_2"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Prod_1"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Shape_3"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Prod_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Cast"
  op: "Cast"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/truediv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_7"
  op: "AddN"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/truediv"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_7"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_7"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Neg"
  op: "Neg"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Neg"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/RealDiv_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Neg"
  op: "Neg"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Neg"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/RealDiv_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/mul_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dropout/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Reshape_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul/x"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Reshape_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul/x"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.1283792
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/Square"
  op: "Square"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv"
  input: "^gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/Neg"
  op: "Neg"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/Square"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/Exp"
  op: "Exp"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/Neg"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/mul_1"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/Exp"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/mul_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Sqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Neg"
  op: "Neg"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Neg"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Sqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/RealDiv_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Sqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.1283792
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/Square"
  op: "Square"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv"
  input: "^gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/add_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/Neg"
  op: "Neg"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/Square"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/Exp"
  op: "Exp"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/Neg"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/mul_1"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/Exp"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_8"
  op: "AddN"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Reshape"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/AddN_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/mul_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Sqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Neg"
  op: "Neg"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Neg"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Sqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/RealDiv_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Sqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/Erf_grad/mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/AddN_8"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1"
  input: "gradients/AddN_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/AddN_9"
  op: "AddN"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/truediv_grad/Reshape"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/AddN_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/AddN_10"
  op: "AddN"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_10"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_10"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/AddN_9"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1"
  input: "gradients/AddN_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Neg"
  op: "Neg"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Neg"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_11"
  op: "AddN"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/add_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_11"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_11"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Neg"
  op: "Neg"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Neg"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_12"
  op: "AddN"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Mul"
  op: "Mul"
  input: "gradients/AddN_12"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/AddN_12"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  op: "RsqrtGrad"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_13"
  op: "AddN"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Mul"
  op: "Mul"
  input: "gradients/AddN_13"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/AddN_13"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  op: "RsqrtGrad"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance/reduction_indices"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/mod"
  op: "FloorMod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/add"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/range"
  op: "Range"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/range/start"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Size"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Fill"
  op: "Fill"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/range"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/mod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Maximum"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Tile"
  op: "Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape_2"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape_3"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Prod"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape_2"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Prod_1"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape_3"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Prod_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Cast"
  op: "Cast"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/truediv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar"
  op: "Const"
  input: "^gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 2.0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient"
  input: "^gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Neg"
  op: "Neg"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance/reduction_indices"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/mod"
  op: "FloorMod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/add"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/range"
  op: "Range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/range/start"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Size"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Fill"
  op: "Fill"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/mod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Maximum"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Tile"
  op: "Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape_2"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape_3"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Prod"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape_2"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Prod_1"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Shape_3"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Prod_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Cast"
  op: "Cast"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/truediv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar"
  op: "Const"
  input: "^gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 2.0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient"
  input: "^gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Neg"
  op: "Neg"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean/reduction_indices"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/mod"
  op: "FloorMod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/add"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/range"
  op: "Range"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/range/start"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Size"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Fill"
  op: "Fill"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/range"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/mod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Maximum"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Tile"
  op: "Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape_2"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape_3"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Prod"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape_2"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Prod_1"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape_3"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Prod_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Cast"
  op: "Cast"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/truediv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_14"
  op: "AddN"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/truediv"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_14"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_14"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean/reduction_indices"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/mod"
  op: "FloorMod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/add"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/range"
  op: "Range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/range/start"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Size"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Fill"
  op: "Fill"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/mod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Maximum"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Tile"
  op: "Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape_2"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape_3"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Prod"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape_2"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Prod_1"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Shape_3"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Prod_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Cast"
  op: "Cast"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/truediv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_15"
  op: "AddN"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/truediv"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_15"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_15"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Neg"
  op: "Neg"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Neg"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/RealDiv_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Neg"
  op: "Neg"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Neg"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/RealDiv_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/mul_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dropout/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3/perm"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3_grad/transpose"
  op: "Transpose"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_1_grad/MatMul"
  op: "BatchMatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3_grad/transpose"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: false
    }
  }
  attr {
    key: "adj_y"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_1_grad/MatMul_1"
  op: "BatchMatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3_grad/transpose"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: true
    }
  }
  attr {
    key: "adj_y"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3/perm"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3_grad/transpose"
  op: "Transpose"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_3_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_1_grad/MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_1_grad/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2/perm"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2_grad/transpose"
  op: "Transpose"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_1_grad/MatMul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_1_grad/MatMul"
  op: "BatchMatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3_grad/transpose"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: false
    }
  }
  attr {
    key: "adj_y"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_1_grad/MatMul_1"
  op: "BatchMatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_3_grad/transpose"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: true
    }
  }
  attr {
    key: "adj_y"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Neg"
  op: "Neg"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Neg"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/RealDiv_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2_grad/transpose"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_1_grad/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_1_grad/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2/perm"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2_grad/transpose"
  op: "Transpose"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_1_grad/MatMul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/Sum/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/Sum/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/sub"
  op: "Sub"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/Sum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/mul_1"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Neg"
  op: "Neg"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Neg"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/RealDiv_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/mul_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_2_grad/transpose"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/Sum/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/Sum/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/sub"
  op: "Sub"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/dropout/div_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/Sum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/mul_1"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Softmax_grad/mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_2_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_grad/MatMul"
  op: "BatchMatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: false
    }
  }
  attr {
    key: "adj_y"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_grad/MatMul_1"
  op: "BatchMatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: true
    }
  }
  attr {
    key: "adj_y"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/add_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose/perm"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_grad/transpose"
  op: "Transpose"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_grad/MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1/perm"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1_grad/transpose"
  op: "Transpose"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_grad/MatMul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_grad/MatMul"
  op: "BatchMatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: false
    }
  }
  attr {
    key: "adj_y"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_grad/MatMul_1"
  op: "BatchMatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Mul_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: true
    }
  }
  attr {
    key: "adj_y"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_grad/transpose"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1_grad/transpose"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose/perm"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_grad/transpose"
  op: "Transpose"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_grad/MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1/perm"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1_grad/transpose"
  op: "Transpose"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/MatMul_grad/MatMul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_grad/transpose"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/transpose_1_grad/transpose"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/AddN_16"
  op: "AddN"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_16"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_16"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/Reshape_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Neg"
  op: "Neg"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Neg"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_17"
  op: "AddN"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/add_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_17"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_17"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Neg"
  op: "Neg"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Neg"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_18"
  op: "AddN"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Mul"
  op: "Mul"
  input: "gradients/AddN_18"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/AddN_18"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  op: "RsqrtGrad"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_19"
  op: "AddN"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Mul"
  op: "Mul"
  input: "gradients/AddN_19"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/AddN_19"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  op: "RsqrtGrad"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance/reduction_indices"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/mod"
  op: "FloorMod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/add"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/range"
  op: "Range"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/range/start"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Size"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Fill"
  op: "Fill"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/range"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/mod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Maximum"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Tile"
  op: "Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape_2"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape_3"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Prod"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape_2"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Prod_1"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape_3"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Prod_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Cast"
  op: "Cast"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/truediv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/scalar"
  op: "Const"
  input: "^gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 2.0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/scalar"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/StopGradient"
  input: "^gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Neg"
  op: "Neg"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance/reduction_indices"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/mod"
  op: "FloorMod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/add"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/range"
  op: "Range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/range/start"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Size"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Fill"
  op: "Fill"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/mod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Maximum"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Tile"
  op: "Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape_2"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape_3"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Prod"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape_2"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Prod_1"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Shape_3"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Prod_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Cast"
  op: "Cast"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/truediv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/scalar"
  op: "Const"
  input: "^gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 2.0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/scalar"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/StopGradient"
  input: "^gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Neg"
  op: "Neg"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean/reduction_indices"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/mod"
  op: "FloorMod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/add"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/range"
  op: "Range"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/range/start"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Size"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Fill"
  op: "Fill"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/range"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/mod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Maximum"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Tile"
  op: "Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape_2"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape_3"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Prod"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape_2"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Prod_1"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape_3"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Prod_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Cast"
  op: "Cast"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/truediv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_20"
  op: "AddN"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/truediv"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_20"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_20"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean/reduction_indices"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/mod"
  op: "FloorMod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/add"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/range"
  op: "Range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/range/start"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Size"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Fill"
  op: "Fill"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/mod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Maximum"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Tile"
  op: "Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape_2"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape_3"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Prod"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape_2"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Prod_1"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Shape_3"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Prod_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Cast"
  op: "Cast"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/truediv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_21"
  op: "AddN"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/truediv"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_21"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_21"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Neg"
  op: "Neg"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Neg"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/RealDiv_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Neg"
  op: "Neg"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Neg"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/RealDiv_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/mul_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dropout/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Reshape_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul/x"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Reshape_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul/x"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.1283792
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/Square"
  op: "Square"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv"
  input: "^gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/Neg"
  op: "Neg"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/Square"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/Exp"
  op: "Exp"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/Neg"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/mul_1"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/Exp"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/mul_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Sqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Neg"
  op: "Neg"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Neg"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Sqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/RealDiv_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Sqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.1283792
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/Square"
  op: "Square"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv"
  input: "^gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/add_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/Neg"
  op: "Neg"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/Square"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/Exp"
  op: "Exp"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/Neg"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/mul_1"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/Exp"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_22"
  op: "AddN"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Reshape"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/AddN_22"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/mul_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Sqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Neg"
  op: "Neg"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Neg"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Sqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/RealDiv_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Sqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/Erf_grad/mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/AddN_22"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1"
  input: "gradients/AddN_22"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/AddN_23"
  op: "AddN"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/truediv_grad/Reshape"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/AddN_23"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/AddN_24"
  op: "AddN"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_24"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_24"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/AddN_23"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1"
  input: "gradients/AddN_23"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Neg"
  op: "Neg"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Neg"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_25"
  op: "AddN"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/add_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_25"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_25"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Neg"
  op: "Neg"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Neg"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_26"
  op: "AddN"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Mul"
  op: "Mul"
  input: "gradients/AddN_26"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/AddN_26"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  op: "RsqrtGrad"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_27"
  op: "AddN"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Mul"
  op: "Mul"
  input: "gradients/AddN_27"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/AddN_27"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  op: "RsqrtGrad"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance/reduction_indices"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/mod"
  op: "FloorMod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/add"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/range"
  op: "Range"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/range/start"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Size"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Fill"
  op: "Fill"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/range"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/mod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Maximum"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Tile"
  op: "Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape_2"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape_3"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Prod"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape_2"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Prod_1"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape_3"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Prod_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Cast"
  op: "Cast"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/truediv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar"
  op: "Const"
  input: "^gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 2.0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient"
  input: "^gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Neg"
  op: "Neg"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance/reduction_indices"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/mod"
  op: "FloorMod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/add"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/range"
  op: "Range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/range/start"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Size"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Fill"
  op: "Fill"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/mod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Maximum"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Tile"
  op: "Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape_2"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape_3"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Prod"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape_2"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Prod_1"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Shape_3"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Prod_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Cast"
  op: "Cast"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/truediv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar"
  op: "Const"
  input: "^gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 2.0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient"
  input: "^gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Neg"
  op: "Neg"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean/reduction_indices"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/mod"
  op: "FloorMod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/add"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/range"
  op: "Range"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/range/start"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Size"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Fill"
  op: "Fill"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/range"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/mod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Maximum"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Tile"
  op: "Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape_2"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape_3"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Prod"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape_2"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Prod_1"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape_3"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Prod_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Cast"
  op: "Cast"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/truediv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_28"
  op: "AddN"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/truediv"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_28"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_28"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean/reduction_indices"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/mod"
  op: "FloorMod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/add"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/range"
  op: "Range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/range/start"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Size"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Fill"
  op: "Fill"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/mod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Maximum"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Tile"
  op: "Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape_2"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape_3"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Prod"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape_2"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Prod_1"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Shape_3"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Prod_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Cast"
  op: "Cast"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/truediv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_29"
  op: "AddN"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/truediv"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_29"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_29"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Neg"
  op: "Neg"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Neg"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/RealDiv_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Neg"
  op: "Neg"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Neg"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/RealDiv_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/mul_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dropout/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3/perm"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3_grad/transpose"
  op: "Transpose"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_1_grad/MatMul"
  op: "BatchMatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3_grad/transpose"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: false
    }
  }
  attr {
    key: "adj_y"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_1_grad/MatMul_1"
  op: "BatchMatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3_grad/transpose"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: true
    }
  }
  attr {
    key: "adj_y"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3/perm"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3_grad/transpose"
  op: "Transpose"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_3_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_1_grad/MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_1_grad/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2/perm"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2_grad/transpose"
  op: "Transpose"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_1_grad/MatMul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_1_grad/MatMul"
  op: "BatchMatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3_grad/transpose"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: false
    }
  }
  attr {
    key: "adj_y"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_1_grad/MatMul_1"
  op: "BatchMatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_3_grad/transpose"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: true
    }
  }
  attr {
    key: "adj_y"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Neg"
  op: "Neg"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Neg"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/RealDiv_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2_grad/transpose"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_1_grad/MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_1_grad/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2/perm"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2_grad/transpose"
  op: "Transpose"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_1_grad/MatMul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/Sum/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/Sum/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/sub"
  op: "Sub"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/Sum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/mul_1"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/sub"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Neg"
  op: "Neg"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Neg"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/RealDiv_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/mul_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_2_grad/transpose"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/Sum/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/Sum/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/sub"
  op: "Sub"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/dropout/div_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/Sum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/mul_1"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/sub"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Softmax_grad/mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_2_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_grad/MatMul"
  op: "BatchMatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: false
    }
  }
  attr {
    key: "adj_y"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_grad/MatMul_1"
  op: "BatchMatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: true
    }
  }
  attr {
    key: "adj_y"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/add_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose/perm"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_grad/transpose"
  op: "Transpose"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_grad/MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1/perm"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1_grad/transpose"
  op: "Transpose"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_grad/MatMul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_grad/MatMul"
  op: "BatchMatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: false
    }
  }
  attr {
    key: "adj_y"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_grad/MatMul_1"
  op: "BatchMatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Mul_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "adj_x"
    value {
      b: true
    }
  }
  attr {
    key: "adj_y"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_grad/transpose"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1_grad/transpose"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose/perm"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_grad/transpose"
  op: "Transpose"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_grad/MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1_grad/InvertPermutation"
  op: "InvertPermutation"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1/perm"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1_grad/transpose"
  op: "Transpose"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/MatMul_grad/MatMul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1_grad/InvertPermutation"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tperm"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_grad/transpose"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/transpose_1_grad/transpose"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/encoder/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/AddN_30"
  op: "AddN"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/Reshape_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/encoder/Reshape_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/AddN_30"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/Reshape_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/Reshape_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/div"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/Reshape_1_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/div"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/Reshape_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_31"
  op: "AddN"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/add_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/Reshape_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/Reshape_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/AddN_31"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/Reshape_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/Neg"
  op: "Neg"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/Neg"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/RealDiv_1"
  input: "query_encoder/self_attention_encoder/bert/embeddings/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/mul_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/Reshape_1_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/Reshape_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/dropout/div_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/Neg"
  op: "Neg"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/Neg"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/RealDiv_1"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/dropout/keep_prob"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/mul_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/embeddings/add_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Neg"
  op: "Neg"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Neg"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/dropout/div_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Reshape_1"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/add_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_1_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Neg"
  op: "Neg"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Neg"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_32"
  op: "AddN"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/Rsqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Mul"
  op: "Mul"
  input: "gradients/AddN_32"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/AddN_32"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Reshape_1"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  op: "RsqrtGrad"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_33"
  op: "AddN"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Reshape_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/Rsqrt"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 128
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Mul"
  op: "Mul"
  input: "gradients/AddN_33"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/AddN_33"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  op: "RsqrtGrad"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/Rsqrt"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 3
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance/reduction_indices"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/mod"
  op: "FloorMod"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/add"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/range"
  op: "Range"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/range/start"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Size"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Fill"
  op: "Fill"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/range"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/mod"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Maximum"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Tile"
  op: "Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape_2"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape_3"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Prod"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape_2"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Prod_1"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape_3"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Prod_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Cast"
  op: "Cast"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/truediv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/scalar"
  op: "Const"
  input: "^gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 2.0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/scalar"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/sub"
  op: "Sub"
  input: "query_encoder/self_attention_encoder/bert/embeddings/add_1"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/StopGradient"
  input: "^gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/mul_1"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Neg"
  op: "Neg"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 3
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance/reduction_indices"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/mod"
  op: "FloorMod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/add"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/range"
  op: "Range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/range/start"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Size"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Fill"
  op: "Fill"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/mod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Maximum"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/add_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Tile"
  op: "Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape_2"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape_3"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Prod"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape_2"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Prod_1"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Shape_3"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Prod_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Cast"
  op: "Cast"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/truediv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/StopGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/scalar"
  op: "Const"
  input: "^gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 2.0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/scalar"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/sub"
  op: "Sub"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/add_1"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/StopGradient"
  input: "^gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/variance_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/mul_1"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Neg"
  op: "Neg"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 3
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/add"
  op: "Add"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean/reduction_indices"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/mod"
  op: "FloorMod"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/add"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/range"
  op: "Range"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/range/start"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Size"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Fill"
  op: "Fill"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/range"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/mod"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Maximum"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/DynamicStitch"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Tile"
  op: "Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape_2"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape_3"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Prod"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape_2"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Prod_1"
  op: "Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape_3"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Prod_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Prod"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Cast"
  op: "Cast"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/truediv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Tile"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_34"
  op: "AddN"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/truediv"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_1_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\001\000\000\000\036\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_1_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_1_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_34"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_1_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_34"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_1_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 3
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/add"
  op: "Add"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean/reduction_indices"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/mod"
  op: "FloorMod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/add"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/range"
  op: "Range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/range/start"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Size"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Fill"
  op: "Fill"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/range"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/mod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Maximum"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/DynamicStitch"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Tile"
  op: "Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape_2"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape_3"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Prod"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape_2"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Prod_1"
  op: "Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Shape_3"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Const_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Maximum_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Maximum_1"
  op: "Maximum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Prod_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Maximum_1/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/floordiv_1"
  op: "FloorDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Prod"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Maximum_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Cast"
  op: "Cast"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/truediv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Tile"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/dropout_2/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_1_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_1_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Reshape_2_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\036\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Reshape_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_1_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Reshape_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_35"
  op: "AddN"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/moments/mean_grad/truediv"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_1_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\001\000\000\000\310\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_1_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_1_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_35"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_1_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_35"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_1_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/dropout_2/div"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/dropout_2/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_grad/Reshape"
  input: "query_encoder/self_attention_encoder/dropout_2/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/dropout_2/div"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Reshape_1_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Reshape_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/add_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Reshape_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\036\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/stack/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/stack"
  op: "Pack"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/Rank"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/stack/1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/Reshape"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/Slice/begin"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/stack"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/sub"
  op: "Sub"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/Shape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/sub_1"
  op: "Sub"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/sub"
  input: "query_encoder/self_attention_encoder/bert/embeddings/Slice/begin"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/sub_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/stack"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/concat"
  op: "ConcatV2"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/concat/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/Pad"
  op: "Pad"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Reshape_2_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tpaddings"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/dropout_2/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_1_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_1_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_2_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\310\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_1_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/Tanh_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/Reshape"
  input: "query_encoder/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/Neg"
  op: "Neg"
  input: "query_encoder/self_attention_encoder/Tanh_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/Neg"
  input: "query_encoder/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/RealDiv_1"
  input: "query_encoder/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/mul_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Reshape_1_grad/Reshape"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/bert/embeddings/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "query_encoder/self_attention_encoder/bert/embeddings/one_hot"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Reshape_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/dropout_2/div"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/dropout_2/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/dropout_2/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/dropout_2/div"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_1_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/add_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\310\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/stack/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/stack"
  op: "Pack"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/Rank"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/stack/1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/Reshape"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/Slice/begin"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/stack"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/sub"
  op: "Sub"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/Shape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/sub_1"
  op: "Sub"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/sub"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/Slice/begin"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/sub_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/stack"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/concat"
  op: "ConcatV2"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/concat/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/Pad"
  op: "Pad"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_2_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tpaddings"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Tanh_1_grad/TanhGrad"
  op: "TanhGrad"
  input: "query_encoder/self_attention_encoder/Tanh_1"
  input: "gradients/query_encoder/self_attention_encoder/dropout_2/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/Tanh_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/Neg"
  op: "Neg"
  input: "code_encoder/python/self_attention_encoder/Tanh_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/Neg"
  input: "code_encoder/python/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/RealDiv_1"
  input: "code_encoder/python/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/mul_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_1_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/one_hot"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Reshape_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/add_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/conv1d_1/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/add_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/dropout_1/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/add_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/add_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/Tanh_1_grad/TanhGrad"
  input: "gradients/query_encoder/self_attention_encoder/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/add_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/Tanh_1_grad/TanhGrad"
  input: "gradients/query_encoder/self_attention_encoder/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/add_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Tanh_1_grad/TanhGrad"
  op: "TanhGrad"
  input: "code_encoder/python/self_attention_encoder/Tanh_1"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_2/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d_1/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/query_encoder/self_attention_encoder/add_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/add_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/add_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/dropout_1/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/add_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/add_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/Tanh_1_grad/TanhGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/add_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/Tanh_1_grad/TanhGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/add_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/Squeeze_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/conv1d_1/conv1d/Conv2D"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/Squeeze_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/add_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/Squeeze_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/add_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/Conv2D_grad/ShapeN"
  op: "ShapeN"
  input: "query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims"
  input: "query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/Conv2D_grad/Conv2DBackpropInput"
  op: "Conv2DBackpropInput"
  input: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/Conv2D_grad/ShapeN"
  input: "query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1"
  input: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/Squeeze_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
  attr {
    key: "dilations"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "padding"
    value {
      s: "SAME"
    }
  }
  attr {
    key: "strides"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "use_cudnn_on_gpu"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/Conv2D_grad/Conv2DBackpropFilter"
  op: "Conv2DBackpropFilter"
  input: "query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims"
  input: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/Conv2D_grad/ShapeN:1"
  input: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/Squeeze_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
  attr {
    key: "dilations"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "padding"
    value {
      s: "SAME"
    }
  }
  attr {
    key: "strides"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "use_cudnn_on_gpu"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/Squeeze_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/conv1d/Conv2D"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/Squeeze_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/add_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/Squeeze_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/dropout_1/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/Conv2D_grad/Conv2DBackpropInput"
  input: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\010\000\000\000\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/Conv2D_grad/Conv2DBackpropFilter"
  input: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/Conv2D_grad/ShapeN"
  op: "ShapeN"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/Conv2D_grad/Conv2DBackpropInput"
  op: "Conv2DBackpropInput"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/Conv2D_grad/ShapeN"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/Squeeze_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
  attr {
    key: "dilations"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "padding"
    value {
      s: "SAME"
    }
  }
  attr {
    key: "strides"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "use_cudnn_on_gpu"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/Conv2D_grad/Conv2DBackpropFilter"
  op: "Conv2DBackpropFilter"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/Conv2D_grad/ShapeN:1"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/Squeeze_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
  attr {
    key: "dilations"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "padding"
    value {
      s: "SAME"
    }
  }
  attr {
    key: "strides"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "use_cudnn_on_gpu"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/AddN_36"
  op: "AddN"
  input: "gradients/query_encoder/self_attention_encoder/add_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims_grad/Reshape"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/add_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/dropout_1/div"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/Shape_1"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/dropout_1/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/Mul"
  op: "Mul"
  input: "gradients/AddN_36"
  input: "query_encoder/self_attention_encoder/dropout_1/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/dropout_1/div"
  input: "gradients/AddN_36"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/dropout_1/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/Conv2D_grad/Conv2DBackpropInput"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\010\000\000\000\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/Conv2D_grad/Conv2DBackpropFilter"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/Reshape"
  input: "query_encoder/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/Neg"
  op: "Neg"
  input: "query_encoder/self_attention_encoder/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/Neg"
  input: "query_encoder/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/RealDiv_1"
  input: "query_encoder/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/mul_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_37"
  op: "AddN"
  input: "gradients/code_encoder/python/self_attention_encoder/add_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims_grad/Reshape"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/add_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/dropout_1/div"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/Shape_1"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/dropout_1/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/Mul"
  op: "Mul"
  input: "gradients/AddN_37"
  input: "code_encoder/python/self_attention_encoder/dropout_1/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/dropout_1/div"
  input: "gradients/AddN_37"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/Tanh_grad/TanhGrad"
  op: "TanhGrad"
  input: "query_encoder/self_attention_encoder/Tanh"
  input: "gradients/query_encoder/self_attention_encoder/dropout_1/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/Neg"
  op: "Neg"
  input: "code_encoder/python/self_attention_encoder/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/Neg"
  input: "code_encoder/python/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/RealDiv_1"
  input: "code_encoder/python/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/mul_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/query_encoder/self_attention_encoder/Tanh_grad/TanhGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/Tanh_grad/TanhGrad"
  op: "TanhGrad"
  input: "code_encoder/python/self_attention_encoder/Tanh"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout_1/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/Squeeze_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/conv1d/conv1d/Conv2D"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/Squeeze_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/Tanh_grad/TanhGrad"
  input: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/Squeeze_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/Tanh_grad/TanhGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/Conv2D_grad/ShapeN"
  op: "ShapeN"
  input: "query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims"
  input: "query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/Conv2D_grad/Conv2DBackpropInput"
  op: "Conv2DBackpropInput"
  input: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/Conv2D_grad/ShapeN"
  input: "query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims_1"
  input: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/Squeeze_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
  attr {
    key: "dilations"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "padding"
    value {
      s: "SAME"
    }
  }
  attr {
    key: "strides"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "use_cudnn_on_gpu"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/Conv2D_grad/Conv2DBackpropFilter"
  op: "Conv2DBackpropFilter"
  input: "query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims"
  input: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/Conv2D_grad/ShapeN:1"
  input: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/Squeeze_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
  attr {
    key: "dilations"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "padding"
    value {
      s: "SAME"
    }
  }
  attr {
    key: "strides"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "use_cudnn_on_gpu"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/Squeeze_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/conv1d/conv1d/Conv2D"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/Squeeze_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/Tanh_grad/TanhGrad"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/Squeeze_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims_grad/Shape"
  op: "Shape"
  input: "query_encoder/self_attention_encoder/embedding_lookup/Identity"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/Conv2D_grad/Conv2DBackpropInput"
  input: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims_1_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\010\000\000\000\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/Conv2D_grad/Conv2DBackpropFilter"
  input: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/Conv2D_grad/ShapeN"
  op: "ShapeN"
  input: "code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims"
  input: "code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/Conv2D_grad/Conv2DBackpropInput"
  op: "Conv2DBackpropInput"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/Conv2D_grad/ShapeN"
  input: "code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims_1"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/Squeeze_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
  attr {
    key: "dilations"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "padding"
    value {
      s: "SAME"
    }
  }
  attr {
    key: "strides"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "use_cudnn_on_gpu"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/Conv2D_grad/Conv2DBackpropFilter"
  op: "Conv2DBackpropFilter"
  input: "code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/Conv2D_grad/ShapeN:1"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/Squeeze_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
  attr {
    key: "dilations"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "padding"
    value {
      s: "SAME"
    }
  }
  attr {
    key: "strides"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "use_cudnn_on_gpu"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims_grad/Shape"
  op: "Shape"
  input: "code_encoder/python/self_attention_encoder/embedding_lookup/Identity"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/Conv2D_grad/Conv2DBackpropInput"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims_1_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\010\000\000\000\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/Conv2D_grad/Conv2DBackpropFilter"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/Shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dropout/mul"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT64
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\'\000\000\000\000\000\000\200\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/ToInt32"
  op: "Cast"
  input: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/Shape"
  attr {
    key: "DstT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dropout/mul"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/Size"
  op: "Size"
  input: "query_encoder/self_attention_encoder/tokens"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/ExpandDims"
  op: "ExpandDims"
  input: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/Size"
  input: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/strided_slice"
  op: "StridedSlice"
  input: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/ToInt32"
  input: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/strided_slice/stack"
  input: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/strided_slice/stack_1"
  input: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 1
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 0
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/concat"
  op: "ConcatV2"
  input: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/ExpandDims"
  input: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/strided_slice"
  input: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/concat/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/Reshape_1"
  op: "Reshape"
  input: "query_encoder/self_attention_encoder/tokens"
  input: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\'\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\'\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul/strided_slice"
  op: "StridedSlice"
  input: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/ToInt32"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul/strided_slice/stack"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul/strided_slice/stack_1"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul/x"
  op: "UnsortedSegmentSum"
  input: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul/strided_slice"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tnumsegments"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul/x"
  input: "query_encoder/self_attention_encoder/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul_1/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul_1/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul_1/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul_1/strided_slice"
  op: "StridedSlice"
  input: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/ToInt32"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul_1/strided_slice/stack"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul_1/strided_slice/stack_1"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul_1/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul_1/y"
  op: "UnsortedSegmentSum"
  input: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/embedding_lookup_grad/Reshape_1"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul_1/strided_slice"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tnumsegments"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul_1"
  op: "Mul"
  input: "query_encoder/self_attention_encoder/dropout/div"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul_1/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Mul_1"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/Shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dropout/mul"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT64
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\'\000\000\000\000\000\000\200\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/ToInt32"
  op: "Cast"
  input: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/Shape"
  attr {
    key: "DstT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "Truncate"
    value {
      b: false
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dropout/mul"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/Size"
  op: "Size"
  input: "code_encoder/python/self_attention_encoder/tokens"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/ExpandDims"
  op: "ExpandDims"
  input: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/Size"
  input: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/strided_slice"
  op: "StridedSlice"
  input: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/ToInt32"
  input: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/strided_slice/stack"
  input: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/strided_slice/stack_1"
  input: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 1
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 0
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/concat"
  op: "ConcatV2"
  input: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/ExpandDims"
  input: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/strided_slice"
  input: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/concat/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/Reshape_1"
  op: "Reshape"
  input: "code_encoder/python/self_attention_encoder/tokens"
  input: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\'\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/Shape"
  input: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Reshape"
  input: "query_encoder/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/Sum"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/Sum"
  input: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/Neg"
  op: "Neg"
  input: "query_encoder/self_attention_encoder/token_embeddings/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/Neg"
  input: "query_encoder/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/RealDiv_1"
  input: "query_encoder/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/mul"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/dropout/mul_grad/Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/mul"
  input: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/Sum_1"
  input: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\'\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\'\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul/strided_slice"
  op: "StridedSlice"
  input: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/ToInt32"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul/strided_slice/stack"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul/strided_slice/stack_1"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul/x"
  op: "UnsortedSegmentSum"
  input: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul/strided_slice"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tnumsegments"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul/x"
  input: "code_encoder/python/self_attention_encoder/dropout/Floor"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul_1/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul_1/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul_1/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul_1/strided_slice"
  op: "StridedSlice"
  input: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/ToInt32"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul_1/strided_slice/stack"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul_1/strided_slice/stack_1"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul_1/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul_1/y"
  op: "UnsortedSegmentSum"
  input: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/embedding_lookup_grad/Reshape_1"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul_1/strided_slice"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tnumsegments"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul_1"
  op: "Mul"
  input: "code_encoder/python/self_attention_encoder/dropout/div"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul_1/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Mul_1"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\'\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/Shape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Reshape"
  input: "code_encoder/python/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/Sum"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/Reshape"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/Neg"
  op: "Neg"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/Neg"
  input: "code_encoder/python/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/RealDiv_1"
  input: "code_encoder/python/self_attention_encoder/dropout_keep_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/mul"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/mul_grad/Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/Sum_1"
  op: "Sum"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/mul"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/Sum_1"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "global_norm/L2Loss"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/Reshape"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_1"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_2"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/conv1d/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_3"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_4"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/conv1d_1/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_5"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_6"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/Pad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/Pad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_7"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_8"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_9"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_10"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_11"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_12"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_13"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_14"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_15"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_16"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_17"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_18"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_19"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_20"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_21"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_22"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_23"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_24"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_25"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_26"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_27"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_28"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_29"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_30"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_31"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_32"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_33"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_34"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_35"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_36"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_37"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_38"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_39"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_40"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_41"
  op: "L2Loss"
  input: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/transpose_1_grad/transpose"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/transpose_1_grad/transpose"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_42"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/dropout/div_grad/Reshape"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_43"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_44"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/conv1d/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/conv1d/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_45"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_46"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/conv1d_1/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/conv1d_1/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_47"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_48"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/Pad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/Pad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_49"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_50"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_51"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_52"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_53"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_54"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_55"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_56"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_57"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_58"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_59"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_60"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_61"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_62"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_63"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_64"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_65"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_66"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_67"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_68"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_69"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_70"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_71"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_72"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_73"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_74"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_75"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_76"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_77"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_78"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_79"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_80"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd_grad/BiasAddGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_81"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_82"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "global_norm/L2Loss_83"
  op: "L2Loss"
  input: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/transpose_1_grad/transpose"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/dense/Tensordot/transpose_1_grad/transpose"
      }
    }
  }
}
node {
  name: "global_norm/stack"
  op: "Pack"
  input: "global_norm/L2Loss"
  input: "global_norm/L2Loss_1"
  input: "global_norm/L2Loss_2"
  input: "global_norm/L2Loss_3"
  input: "global_norm/L2Loss_4"
  input: "global_norm/L2Loss_5"
  input: "global_norm/L2Loss_6"
  input: "global_norm/L2Loss_7"
  input: "global_norm/L2Loss_8"
  input: "global_norm/L2Loss_9"
  input: "global_norm/L2Loss_10"
  input: "global_norm/L2Loss_11"
  input: "global_norm/L2Loss_12"
  input: "global_norm/L2Loss_13"
  input: "global_norm/L2Loss_14"
  input: "global_norm/L2Loss_15"
  input: "global_norm/L2Loss_16"
  input: "global_norm/L2Loss_17"
  input: "global_norm/L2Loss_18"
  input: "global_norm/L2Loss_19"
  input: "global_norm/L2Loss_20"
  input: "global_norm/L2Loss_21"
  input: "global_norm/L2Loss_22"
  input: "global_norm/L2Loss_23"
  input: "global_norm/L2Loss_24"
  input: "global_norm/L2Loss_25"
  input: "global_norm/L2Loss_26"
  input: "global_norm/L2Loss_27"
  input: "global_norm/L2Loss_28"
  input: "global_norm/L2Loss_29"
  input: "global_norm/L2Loss_30"
  input: "global_norm/L2Loss_31"
  input: "global_norm/L2Loss_32"
  input: "global_norm/L2Loss_33"
  input: "global_norm/L2Loss_34"
  input: "global_norm/L2Loss_35"
  input: "global_norm/L2Loss_36"
  input: "global_norm/L2Loss_37"
  input: "global_norm/L2Loss_38"
  input: "global_norm/L2Loss_39"
  input: "global_norm/L2Loss_40"
  input: "global_norm/L2Loss_41"
  input: "global_norm/L2Loss_42"
  input: "global_norm/L2Loss_43"
  input: "global_norm/L2Loss_44"
  input: "global_norm/L2Loss_45"
  input: "global_norm/L2Loss_46"
  input: "global_norm/L2Loss_47"
  input: "global_norm/L2Loss_48"
  input: "global_norm/L2Loss_49"
  input: "global_norm/L2Loss_50"
  input: "global_norm/L2Loss_51"
  input: "global_norm/L2Loss_52"
  input: "global_norm/L2Loss_53"
  input: "global_norm/L2Loss_54"
  input: "global_norm/L2Loss_55"
  input: "global_norm/L2Loss_56"
  input: "global_norm/L2Loss_57"
  input: "global_norm/L2Loss_58"
  input: "global_norm/L2Loss_59"
  input: "global_norm/L2Loss_60"
  input: "global_norm/L2Loss_61"
  input: "global_norm/L2Loss_62"
  input: "global_norm/L2Loss_63"
  input: "global_norm/L2Loss_64"
  input: "global_norm/L2Loss_65"
  input: "global_norm/L2Loss_66"
  input: "global_norm/L2Loss_67"
  input: "global_norm/L2Loss_68"
  input: "global_norm/L2Loss_69"
  input: "global_norm/L2Loss_70"
  input: "global_norm/L2Loss_71"
  input: "global_norm/L2Loss_72"
  input: "global_norm/L2Loss_73"
  input: "global_norm/L2Loss_74"
  input: "global_norm/L2Loss_75"
  input: "global_norm/L2Loss_76"
  input: "global_norm/L2Loss_77"
  input: "global_norm/L2Loss_78"
  input: "global_norm/L2Loss_79"
  input: "global_norm/L2Loss_80"
  input: "global_norm/L2Loss_81"
  input: "global_norm/L2Loss_82"
  input: "global_norm/L2Loss_83"
  attr {
    key: "N"
    value {
      i: 84
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "global_norm/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "global_norm/Sum"
  op: "Sum"
  input: "global_norm/stack"
  input: "global_norm/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "global_norm/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 2.0
      }
    }
  }
}
node {
  name: "global_norm/mul"
  op: "Mul"
  input: "global_norm/Sum"
  input: "global_norm/Const_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/global_norm"
  op: "Sqrt"
  input: "global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "VerifyFinite/CheckNumerics"
  op: "CheckNumerics"
  input: "global_norm/global_norm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@global_norm/global_norm"
      }
    }
  }
  attr {
    key: "message"
    value {
      s: "Found Inf or NaN global norm."
    }
  }
}
node {
  name: "VerifyFinite/control_dependency"
  op: "Identity"
  input: "global_norm/global_norm"
  input: "^VerifyFinite/CheckNumerics"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@global_norm/global_norm"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/truediv/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "clip_by_global_norm/truediv"
  op: "RealDiv"
  input: "clip_by_global_norm/truediv/x"
  input: "VerifyFinite/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "clip_by_global_norm/truediv_1/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "clip_by_global_norm/truediv_1"
  op: "RealDiv"
  input: "clip_by_global_norm/Const"
  input: "clip_by_global_norm/truediv_1/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/Minimum"
  op: "Minimum"
  input: "clip_by_global_norm/truediv"
  input: "clip_by_global_norm/truediv_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/mul/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul"
  op: "Mul"
  input: "clip_by_global_norm/mul/x"
  input: "clip_by_global_norm/Minimum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/mul_1"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/Reshape"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_0"
  op: "Identity"
  input: "clip_by_global_norm/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/dropout/div_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_2"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims_1_grad/Reshape"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_1"
  op: "Identity"
  input: "clip_by_global_norm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/conv1d/conv1d/ExpandDims_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_3"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/conv1d/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_2"
  op: "Identity"
  input: "clip_by_global_norm/mul_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/conv1d/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_4"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1_grad/Reshape"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_3"
  op: "Identity"
  input: "clip_by_global_norm/mul_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_5"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/conv1d_1/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/conv1d_1/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_4"
  op: "Identity"
  input: "clip_by_global_norm/mul_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/conv1d_1/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_6"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_5"
  op: "Identity"
  input: "clip_by_global_norm/mul_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_7"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/Pad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/Pad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_6"
  op: "Identity"
  input: "clip_by_global_norm/mul_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/Slice_grad/Pad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_8"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Reshape"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_7"
  op: "Identity"
  input: "clip_by_global_norm/mul_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_9"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Reshape_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_8"
  op: "Identity"
  input: "clip_by_global_norm/mul_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_10"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_9"
  op: "Identity"
  input: "clip_by_global_norm/mul_10"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_11"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_10"
  op: "Identity"
  input: "clip_by_global_norm/mul_11"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_12"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_11"
  op: "Identity"
  input: "clip_by_global_norm/mul_12"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_13"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_12"
  op: "Identity"
  input: "clip_by_global_norm/mul_13"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_14"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_13"
  op: "Identity"
  input: "clip_by_global_norm/mul_14"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_15"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_14"
  op: "Identity"
  input: "clip_by_global_norm/mul_15"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_16"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_15"
  op: "Identity"
  input: "clip_by_global_norm/mul_16"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_17"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_16"
  op: "Identity"
  input: "clip_by_global_norm/mul_17"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_18"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_17"
  op: "Identity"
  input: "clip_by_global_norm/mul_18"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_19"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_18"
  op: "Identity"
  input: "clip_by_global_norm/mul_19"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_20"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_19"
  op: "Identity"
  input: "clip_by_global_norm/mul_20"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_21"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_20"
  op: "Identity"
  input: "clip_by_global_norm/mul_21"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_22"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_21"
  op: "Identity"
  input: "clip_by_global_norm/mul_22"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_23"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_22"
  op: "Identity"
  input: "clip_by_global_norm/mul_23"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_24"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Reshape"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_23"
  op: "Identity"
  input: "clip_by_global_norm/mul_24"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_25"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_24"
  op: "Identity"
  input: "clip_by_global_norm/mul_25"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_26"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_25"
  op: "Identity"
  input: "clip_by_global_norm/mul_26"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_27"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_26"
  op: "Identity"
  input: "clip_by_global_norm/mul_27"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_28"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_27"
  op: "Identity"
  input: "clip_by_global_norm/mul_28"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_29"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_28"
  op: "Identity"
  input: "clip_by_global_norm/mul_29"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_30"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_29"
  op: "Identity"
  input: "clip_by_global_norm/mul_30"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_31"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_30"
  op: "Identity"
  input: "clip_by_global_norm/mul_31"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_32"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_31"
  op: "Identity"
  input: "clip_by_global_norm/mul_32"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_33"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_32"
  op: "Identity"
  input: "clip_by_global_norm/mul_33"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_34"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_33"
  op: "Identity"
  input: "clip_by_global_norm/mul_34"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_35"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_34"
  op: "Identity"
  input: "clip_by_global_norm/mul_35"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_36"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_35"
  op: "Identity"
  input: "clip_by_global_norm/mul_36"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_37"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_36"
  op: "Identity"
  input: "clip_by_global_norm/mul_37"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_38"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_37"
  op: "Identity"
  input: "clip_by_global_norm/mul_38"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_39"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_38"
  op: "Identity"
  input: "clip_by_global_norm/mul_39"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_40"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Reshape"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_39"
  op: "Identity"
  input: "clip_by_global_norm/mul_40"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_41"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_40"
  op: "Identity"
  input: "clip_by_global_norm/mul_41"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_42"
  op: "Mul"
  input: "gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/transpose_1_grad/transpose"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/transpose_1_grad/transpose"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_43"
  op: "Identity"
  input: "clip_by_global_norm/mul_42"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/code_encoder/python/self_attention_encoder/dense/Tensordot/transpose_1_grad/transpose"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_43"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/dropout/div_grad/Reshape"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/dropout/div_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_44"
  op: "Identity"
  input: "clip_by_global_norm/mul_43"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/dropout/div_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_44"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims_1_grad/Reshape"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_45"
  op: "Identity"
  input: "clip_by_global_norm/mul_44"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/conv1d/conv1d/ExpandDims_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_45"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/conv1d/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/conv1d/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_46"
  op: "Identity"
  input: "clip_by_global_norm/mul_45"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/conv1d/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_46"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1_grad/Reshape"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_47"
  op: "Identity"
  input: "clip_by_global_norm/mul_46"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/conv1d_1/conv1d/ExpandDims_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_47"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/conv1d_1/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/conv1d_1/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_48"
  op: "Identity"
  input: "clip_by_global_norm/mul_47"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/conv1d_1/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_48"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_49"
  op: "Identity"
  input: "clip_by_global_norm/mul_48"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_49"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/Pad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/Pad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_50"
  op: "Identity"
  input: "clip_by_global_norm/mul_49"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/Slice_grad/Pad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_50"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Reshape"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_51"
  op: "Identity"
  input: "clip_by_global_norm/mul_50"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_51"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Reshape_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_52"
  op: "Identity"
  input: "clip_by_global_norm/mul_51"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_52"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_53"
  op: "Identity"
  input: "clip_by_global_norm/mul_52"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_53"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_54"
  op: "Identity"
  input: "clip_by_global_norm/mul_53"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_54"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_55"
  op: "Identity"
  input: "clip_by_global_norm/mul_54"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_55"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_56"
  op: "Identity"
  input: "clip_by_global_norm/mul_55"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_56"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_57"
  op: "Identity"
  input: "clip_by_global_norm/mul_56"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_57"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_58"
  op: "Identity"
  input: "clip_by_global_norm/mul_57"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_58"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_59"
  op: "Identity"
  input: "clip_by_global_norm/mul_58"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_59"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_60"
  op: "Identity"
  input: "clip_by_global_norm/mul_59"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_60"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_61"
  op: "Identity"
  input: "clip_by_global_norm/mul_60"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_61"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_62"
  op: "Identity"
  input: "clip_by_global_norm/mul_61"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_62"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_63"
  op: "Identity"
  input: "clip_by_global_norm/mul_62"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_63"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_64"
  op: "Identity"
  input: "clip_by_global_norm/mul_63"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_64"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_65"
  op: "Identity"
  input: "clip_by_global_norm/mul_64"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_65"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_66"
  op: "Identity"
  input: "clip_by_global_norm/mul_65"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_66"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Reshape"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_67"
  op: "Identity"
  input: "clip_by_global_norm/mul_66"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_67"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_68"
  op: "Identity"
  input: "clip_by_global_norm/mul_67"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_68"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_69"
  op: "Identity"
  input: "clip_by_global_norm/mul_68"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_69"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_70"
  op: "Identity"
  input: "clip_by_global_norm/mul_69"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_70"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_71"
  op: "Identity"
  input: "clip_by_global_norm/mul_70"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_71"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_72"
  op: "Identity"
  input: "clip_by_global_norm/mul_71"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_72"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_73"
  op: "Identity"
  input: "clip_by_global_norm/mul_72"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_73"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_74"
  op: "Identity"
  input: "clip_by_global_norm/mul_73"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_74"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_75"
  op: "Identity"
  input: "clip_by_global_norm/mul_74"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_75"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_76"
  op: "Identity"
  input: "clip_by_global_norm/mul_75"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_76"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_77"
  op: "Identity"
  input: "clip_by_global_norm/mul_76"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_77"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_78"
  op: "Identity"
  input: "clip_by_global_norm/mul_77"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_78"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_79"
  op: "Identity"
  input: "clip_by_global_norm/mul_78"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_79"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_80"
  op: "Identity"
  input: "clip_by_global_norm/mul_79"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_80"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_81"
  op: "Identity"
  input: "clip_by_global_norm/mul_80"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_81"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd_grad/BiasAddGrad"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_82"
  op: "Identity"
  input: "clip_by_global_norm/mul_81"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_82"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Reshape"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_83"
  op: "Identity"
  input: "clip_by_global_norm/mul_82"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Reshape"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_83"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_84"
  op: "Identity"
  input: "clip_by_global_norm/mul_83"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul_84"
  op: "Mul"
  input: "gradients/query_encoder/self_attention_encoder/dense/Tensordot/transpose_1_grad/transpose"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/dense/Tensordot/transpose_1_grad/transpose"
      }
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_87"
  op: "Identity"
  input: "clip_by_global_norm/mul_84"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/query_encoder/self_attention_encoder/dense/Tensordot/transpose_1_grad/transpose"
      }
    }
  }
}
node {
  name: "Const_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_1"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_0"
  input: "Const_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_3"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_2"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_1"
  input: "Const_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_4"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_3"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_2"
  input: "Const_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_5"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_4"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_3"
  input: "Const_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_6"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_5"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_4"
  input: "Const_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_7"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_6"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_5"
  input: "Const_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_8"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_7"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_6"
  input: "Const_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_9"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_8"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_7"
  input: "Const_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_10"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_9"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_8"
  input: "Const_10"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_11"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_10"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_9"
  input: "Const_11"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_12"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_11"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_10"
  input: "Const_12"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_13"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_12"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_11"
  input: "Const_13"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_14"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_13"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_12"
  input: "Const_14"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_15"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_14"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_13"
  input: "Const_15"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_16"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_15"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_14"
  input: "Const_16"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_17"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_16"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_15"
  input: "Const_17"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_18"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_17"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_16"
  input: "Const_18"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_19"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_18"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_17"
  input: "Const_19"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_20"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_19"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_18"
  input: "Const_20"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_21"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_20"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_19"
  input: "Const_21"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_22"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_21"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_20"
  input: "Const_22"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_23"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_22"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_21"
  input: "Const_23"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_24"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_23"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_22"
  input: "Const_24"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_25"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_24"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_23"
  input: "Const_25"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_26"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_25"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_24"
  input: "Const_26"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_27"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_26"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_25"
  input: "Const_27"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_28"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_27"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_26"
  input: "Const_28"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_29"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_28"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_27"
  input: "Const_29"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_30"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_29"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_28"
  input: "Const_30"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_31"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_30"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_29"
  input: "Const_31"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_32"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_31"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_30"
  input: "Const_32"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_33"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_32"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_31"
  input: "Const_33"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_34"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_33"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_32"
  input: "Const_34"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_35"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_34"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_33"
  input: "Const_35"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_36"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_35"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_34"
  input: "Const_36"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_37"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_36"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_35"
  input: "Const_37"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_38"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_37"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_36"
  input: "Const_38"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_39"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_38"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_37"
  input: "Const_39"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_40"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_39"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_38"
  input: "Const_40"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_41"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_40"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_39"
  input: "Const_41"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_42"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_41"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_40"
  input: "Const_42"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_43"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_42"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_43"
  input: "Const_43"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_44"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_43"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_44"
  input: "Const_44"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_45"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_44"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_45"
  input: "Const_45"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_46"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_45"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_46"
  input: "Const_46"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_47"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_46"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_47"
  input: "Const_47"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_48"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_47"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_48"
  input: "Const_48"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_49"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_48"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_49"
  input: "Const_49"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_50"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_49"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_50"
  input: "Const_50"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_51"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_50"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_51"
  input: "Const_51"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_52"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_51"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_52"
  input: "Const_52"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_53"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_52"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_53"
  input: "Const_53"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_54"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_53"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_54"
  input: "Const_54"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_55"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_54"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_55"
  input: "Const_55"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_56"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_55"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_56"
  input: "Const_56"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_57"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_56"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_57"
  input: "Const_57"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_58"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_57"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_58"
  input: "Const_58"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_59"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_58"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_59"
  input: "Const_59"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_60"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_59"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_60"
  input: "Const_60"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_61"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_60"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_61"
  input: "Const_61"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_62"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_61"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_62"
  input: "Const_62"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_63"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_62"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_63"
  input: "Const_63"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_64"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_63"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_64"
  input: "Const_64"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_65"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_64"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_65"
  input: "Const_65"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_66"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_65"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_66"
  input: "Const_66"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_67"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_66"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_67"
  input: "Const_67"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_68"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_67"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_68"
  input: "Const_68"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_69"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_68"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_69"
  input: "Const_69"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_70"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_69"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_70"
  input: "Const_70"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_71"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_70"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_71"
  input: "Const_71"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_72"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_71"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_72"
  input: "Const_72"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_73"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_72"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_73"
  input: "Const_73"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_74"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_73"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_74"
  input: "Const_74"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_75"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_74"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_75"
  input: "Const_75"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_76"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_75"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_76"
  input: "Const_76"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_77"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_76"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_77"
  input: "Const_77"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_78"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_77"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_78"
  input: "Const_78"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_79"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_78"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_79"
  input: "Const_79"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_80"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_79"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_80"
  input: "Const_80"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_81"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_80"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_81"
  input: "Const_81"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_82"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_81"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_82"
  input: "Const_82"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_83"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_82"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_83"
  input: "Const_83"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_84"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_83"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_84"
  input: "Const_84"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Const_85"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "mul_84"
  op: "Mul"
  input: "clip_by_global_norm/clip_by_global_norm/_87"
  input: "Const_85"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "beta1_power/initial_value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.89999998
      }
    }
  }
}
node {
  name: "beta1_power"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "beta1_power/Assign"
  op: "Assign"
  input: "beta1_power"
  input: "beta1_power/initial_value"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "beta1_power/read"
  op: "Identity"
  input: "beta1_power"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "beta2_power/initial_value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.99900001
      }
    }
  }
}
node {
  name: "beta2_power"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "beta2_power/Assign"
  op: "Assign"
  input: "beta2_power"
  input: "beta2_power/initial_value"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "beta2_power/read"
  op: "Identity"
  input: "beta2_power"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\'\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Adam/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Adam/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 10000
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Adam"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\'\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 10000
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Adam_1"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/token_embeddings/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\010\000\000\000\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\010\000\000\000\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam_1"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/bias/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/conv1d/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/conv1d/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/bias/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/conv1d/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/bias/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/conv1d/bias/Adam_1"
  input: "code_encoder/python/self_attention_encoder/conv1d/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d/bias/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/conv1d/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\010\000\000\000\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\010\000\000\000\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam_1"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/bias/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/bias/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/bias/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/bias/Adam_1"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/conv1d_1/bias/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 16
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 16
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\000\002\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\000\002\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 512
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 512
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\000\002\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\000\002\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 512
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 512
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam_1"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/kernel/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
          dim {
            size: 1
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 1
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/kernel/Adam/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/dense/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/dense/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/kernel/Adam/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/dense/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dense/kernel"
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/kernel/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
          dim {
            size: 1
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 1
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/kernel/Adam_1/Assign"
  op: "Assign"
  input: "code_encoder/python/self_attention_encoder/dense/kernel/Adam_1"
  input: "code_encoder/python/self_attention_encoder/dense/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "code_encoder/python/self_attention_encoder/dense/kernel/Adam_1/read"
  op: "Identity"
  input: "code_encoder/python/self_attention_encoder/dense/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\'\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Adam/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/token_embeddings/Adam/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/token_embeddings/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 10000
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/token_embeddings/Adam"
  input: "query_encoder/self_attention_encoder/token_embeddings/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/token_embeddings/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\'\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/token_embeddings/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/token_embeddings/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 10000
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/token_embeddings/Adam_1"
  input: "query_encoder/self_attention_encoder/token_embeddings/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/token_embeddings/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/token_embeddings/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\010\000\000\000\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Adam"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\010\000\000\000\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Adam_1"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/kernel/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/bias/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/conv1d/bias/Adam"
  input: "query_encoder/self_attention_encoder/conv1d/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/bias/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/conv1d/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/bias/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/conv1d/bias/Adam_1"
  input: "query_encoder/self_attention_encoder/conv1d/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d/bias/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/conv1d/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\010\000\000\000\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\010\000\000\000\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam_1"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/bias/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/conv1d_1/bias/Adam"
  input: "query_encoder/self_attention_encoder/conv1d_1/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/bias/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/conv1d_1/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/bias/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/conv1d_1/bias/Adam_1"
  input: "query_encoder/self_attention_encoder/conv1d_1/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/conv1d_1/bias/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/conv1d_1/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 16
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 16
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\000\002\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\000\002\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 512
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 512
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\000\002\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\200\000\000\000\000\002\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 512
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 512
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\002\000\000\200\000\000\000"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1/Initializer/zeros"
  op: "Fill"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 512
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam_1"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/kernel/Adam/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
          dim {
            size: 1
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/kernel/Adam"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 1
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/kernel/Adam/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/dense/kernel/Adam"
  input: "query_encoder/self_attention_encoder/dense/kernel/Adam/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/kernel/Adam/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/dense/kernel/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dense/kernel"
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/kernel/Adam_1/Initializer/zeros"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
          dim {
            size: 1
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/kernel/Adam_1"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 128
        }
        dim {
          size: 1
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/kernel/Adam_1/Assign"
  op: "Assign"
  input: "query_encoder/self_attention_encoder/dense/kernel/Adam_1"
  input: "query_encoder/self_attention_encoder/dense/kernel/Adam_1/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "query_encoder/self_attention_encoder/dense/kernel/Adam_1/read"
  op: "Identity"
  input: "query_encoder/self_attention_encoder/dense/kernel/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dense/kernel"
      }
    }
  }
}
node {
  name: "Adam/learning_rate"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.00050000002
      }
    }
  }
}
node {
  name: "Adam/beta1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.89999998
      }
    }
  }
}
node {
  name: "Adam/beta2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.99900001
      }
    }
  }
}
node {
  name: "Adam/epsilon"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 9.9999999e-09
      }
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/token_embeddings/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/token_embeddings"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Adam"
  input: "code_encoder/python/self_attention_encoder/token_embeddings/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/conv1d/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/conv1d/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/conv1d/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/conv1d/bias"
  input: "code_encoder/python/self_attention_encoder/conv1d/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/conv1d/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/conv1d_1/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/conv1d_1/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/bias"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/conv1d_1/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_10"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_11"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_12"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_13"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_14"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_15"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_16"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_17"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_18"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_19"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_20"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_21"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_22"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_23"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_24"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_25"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_26"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_27"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_28"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_29"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_30"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_31"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_32"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_33"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_34"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_35"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_36"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_37"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_38"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_39"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_40"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam"
  input: "code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_41"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_code_encoder/python/self_attention_encoder/dense/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "code_encoder/python/self_attention_encoder/dense/kernel"
  input: "code_encoder/python/self_attention_encoder/dense/kernel/Adam"
  input: "code_encoder/python/self_attention_encoder/dense/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_42"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/token_embeddings/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/token_embeddings"
  input: "query_encoder/self_attention_encoder/token_embeddings/Adam"
  input: "query_encoder/self_attention_encoder/token_embeddings/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_43"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/token_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/conv1d/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/conv1d/kernel"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Adam"
  input: "query_encoder/self_attention_encoder/conv1d/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_44"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/conv1d/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/conv1d/bias"
  input: "query_encoder/self_attention_encoder/conv1d/bias/Adam"
  input: "query_encoder/self_attention_encoder/conv1d/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_45"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/conv1d_1/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam"
  input: "query_encoder/self_attention_encoder/conv1d_1/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_46"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/conv1d_1/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/conv1d_1/bias"
  input: "query_encoder/self_attention_encoder/conv1d_1/bias/Adam"
  input: "query_encoder/self_attention_encoder/conv1d_1/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_47"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/conv1d_1/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam"
  input: "query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_48"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam"
  input: "query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_49"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/position_embeddings"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_50"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam"
  input: "query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_51"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_52"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_53"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_54"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_55"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_56"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_57"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_58"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_59"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_60"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_61"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_62"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_63"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_64"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_65"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_66"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_67"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_68"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_69"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_70"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_71"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_72"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_73"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_74"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_75"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_76"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_77"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_78"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_79"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_80"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_81"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_82"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam"
  input: "query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_83"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/update_query_encoder/self_attention_encoder/dense/kernel/ApplyAdam"
  op: "ApplyAdam"
  input: "query_encoder/self_attention_encoder/dense/kernel"
  input: "query_encoder/self_attention_encoder/dense/kernel/Adam"
  input: "query_encoder/self_attention_encoder/dense/kernel/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "Adam/learning_rate"
  input: "Adam/beta1"
  input: "Adam/beta2"
  input: "Adam/epsilon"
  input: "mul_84"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@query_encoder/self_attention_encoder/dense/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "use_nesterov"
    value {
      b: false
    }
  }
}
node {
  name: "Adam/mul"
  op: "Mul"
  input: "beta1_power/read"
  input: "Adam/beta1"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/conv1d/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/conv1d/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/conv1d_1/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/conv1d_1/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/token_embeddings/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/conv1d/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/conv1d/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/conv1d_1/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/conv1d_1/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/token_embeddings/ApplyAdam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "Adam/Assign"
  op: "Assign"
  input: "beta1_power"
  input: "Adam/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "Adam/mul_1"
  op: "Mul"
  input: "beta2_power/read"
  input: "Adam/beta2"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/conv1d/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/conv1d/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/conv1d_1/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/conv1d_1/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/token_embeddings/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/conv1d/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/conv1d/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/conv1d_1/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/conv1d_1/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/token_embeddings/ApplyAdam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
}
node {
  name: "Adam/Assign_1"
  op: "Assign"
  input: "beta2_power"
  input: "Adam/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "Adam"
  op: "NoOp"
  input: "^Adam/Assign"
  input: "^Adam/Assign_1"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/conv1d/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/conv1d/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/conv1d_1/bias/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/conv1d_1/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/dense/kernel/ApplyAdam"
  input: "^Adam/update_code_encoder/python/self_attention_encoder/token_embeddings/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/conv1d/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/conv1d/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/conv1d_1/bias/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/conv1d_1/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/dense/kernel/ApplyAdam"
  input: "^Adam/update_query_encoder/self_attention_encoder/token_embeddings/ApplyAdam"
}
node {
  name: "init"
  op: "NoOp"
  input: "^beta1_power/Assign"
  input: "^beta2_power/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/beta/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/embeddings/position_embeddings/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/embeddings/token_type_embeddings/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/pooler/dense/bias/Assign"
  input: "^code_encoder/python/self_attention_encoder/bert/pooler/dense/kernel/Assign"
  input: "^code_encoder/python/self_attention_encoder/conv1d/bias/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/conv1d/bias/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/conv1d/bias/Assign"
  input: "^code_encoder/python/self_attention_encoder/conv1d/kernel/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/conv1d/kernel/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/conv1d/kernel/Assign"
  input: "^code_encoder/python/self_attention_encoder/conv1d_1/bias/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/conv1d_1/bias/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/conv1d_1/bias/Assign"
  input: "^code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/conv1d_1/kernel/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/conv1d_1/kernel/Assign"
  input: "^code_encoder/python/self_attention_encoder/dense/kernel/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/dense/kernel/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/dense/kernel/Assign"
  input: "^code_encoder/python/self_attention_encoder/token_embeddings/Adam/Assign"
  input: "^code_encoder/python/self_attention_encoder/token_embeddings/Adam_1/Assign"
  input: "^code_encoder/python/self_attention_encoder/token_embeddings/Assign"
  input: "^query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/beta/Assign"
  input: "^query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/embeddings/LayerNorm/gamma/Assign"
  input: "^query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/embeddings/position_embeddings/Assign"
  input: "^query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/embeddings/token_type_embeddings/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/beta/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/LayerNorm/gamma/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/bias/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/output/dense/kernel/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/bias/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/key/kernel/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/bias/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/query/kernel/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/bias/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/attention/self/value/kernel/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/bias/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/intermediate/dense/kernel/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/beta/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/output/LayerNorm/gamma/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/bias/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_0/output/dense/kernel/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/beta/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/LayerNorm/gamma/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/bias/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/output/dense/kernel/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/bias/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/key/kernel/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/bias/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/query/kernel/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/bias/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/attention/self/value/kernel/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/bias/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/intermediate/dense/kernel/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/beta/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/output/LayerNorm/gamma/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/bias/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/bert/encoder/layer_1/output/dense/kernel/Assign"
  input: "^query_encoder/self_attention_encoder/bert/pooler/dense/bias/Assign"
  input: "^query_encoder/self_attention_encoder/bert/pooler/dense/kernel/Assign"
  input: "^query_encoder/self_attention_encoder/conv1d/bias/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/conv1d/bias/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/conv1d/bias/Assign"
  input: "^query_encoder/self_attention_encoder/conv1d/kernel/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/conv1d/kernel/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/conv1d/kernel/Assign"
  input: "^query_encoder/self_attention_encoder/conv1d_1/bias/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/conv1d_1/bias/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/conv1d_1/bias/Assign"
  input: "^query_encoder/self_attention_encoder/conv1d_1/kernel/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/conv1d_1/kernel/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/conv1d_1/kernel/Assign"
  input: "^query_encoder/self_attention_encoder/dense/kernel/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/dense/kernel/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/dense/kernel/Assign"
  input: "^query_encoder/self_attention_encoder/token_embeddings/Adam/Assign"
  input: "^query_encoder/self_attention_encoder/token_embeddings/Adam_1/Assign"
  input: "^query_encoder/self_attention_encoder/token_embeddings/Assign"
}
versions {
  producer: 27
}
